{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac85c40",
   "metadata": {},
   "source": [
    "---\n",
    "title: Instruction on check_evidence.py script\n",
    "author: Vadim Rudakov, rudakow.wadim@gmail.com\n",
    "date: 2026-02-27\n",
    "options:\n",
    "  version: 0.1.0\n",
    "  birth: 2026-02-27\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354dd93",
   "metadata": {},
   "source": [
    "## **1. Architectural Overview: The SVA Principle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95884635",
   "metadata": {},
   "source": [
    "This [script](/tools/scripts/check_evidence.py) validates evidence artifacts (analyses, retrospectives, sources) in `architecture/evidence/` against the schema defined in [`evidence.config.yaml`](/architecture/evidence/evidence.config.yaml).\n",
    "\n",
    "It ensures:\n",
    "- **Required Frontmatter**: Common fields (`id`, `title`, `date`) and type-specific fields are present\n",
    "- **Valid Statuses**: Status values match allowed values per artifact type\n",
    "- **Valid Severity**: Severity levels match allowed values (retrospectives)\n",
    "- **Valid Tags**: Tags are from the shared vocabulary in [`architecture.config.yaml`](/architecture/architecture.config.yaml) (resolved via `parent_config` pointer)\n",
    "- **Naming Convention**: Filenames match regex patterns from config (e.g., `A-26001_slug`, `R-26001_slug`, `S-26001_slug`)\n",
    "- **Date Format**: Date field matches YYYY-MM-DD (ISO 8601)\n",
    "- **Required Sections**: Document contains required `##` headers per type\n",
    "- **Section Whitelist**: Only required + optional sections are permitted; unexpected `##` headers are flagged\n",
    "- **Code Fence Awareness**: `##` headers inside fenced code blocks are ignored during section extraction\n",
    "- **Orphaned Source Detection**: Sources with null `extracted_into` older than configurable threshold produce warnings\n",
    "\n",
    "All validation rules are defined in [`evidence.config.yaml`](/architecture/evidence/evidence.config.yaml) (Single Source of Truth), with shared tags inherited from the parent config.\n",
    "\n",
    "Governed by: [ADR-26035](/architecture/adr/adr_26035_architecture_knowledge_base_taxonomy.md) (Architecture Knowledge Base Taxonomy), [ADR-26036](/architecture/adr/adr_26036_config_file_location_and_naming_conventions.md) (Config File Location and Naming Conventions).\n",
    "\n",
    ":::{hint} **SVA = right tool for the job**\n",
    ":class: dropdown\n",
    "It adheres to the **Smallest Viable Architecture (SVA)** principle.\n",
    "\n",
    "SVA isn't about minimal *code* — it's about **minimal *cognitive and operational overhead***.\n",
    "\n",
    "* **Minimal External Dependencies**: Uses Python standard library (`argparse`, `re`, `subprocess`, `sys`, `pathlib`, `tomllib`) plus `pyyaml` for config parsing.\n",
    "* **Config-Driven Validation**: All rules, field lists, and patterns live in YAML config — no hardcoded values in the script.\n",
    "* **Git Integration**: Optional `--check-staged` mode for pre-commit delta validation.\n",
    "* **Two-Level Config Resolution**: `pyproject.toml [tool.check-evidence]` → `evidence.config.yaml` → `parent_config` pointer → `architecture.config.yaml`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2620fc",
   "metadata": {},
   "source": [
    "## **2. Quick Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01163b62",
   "metadata": {},
   "source": [
    "### Command Cheat Sheet\n",
    "\n",
    "| Task | Command |\n",
    "|------|---------|\n",
    "| Validate all evidence | `uv run tools/scripts/check_evidence.py` |\n",
    "| Verbose validation | `uv run tools/scripts/check_evidence.py --verbose` |\n",
    "| Check staged only | `uv run tools/scripts/check_evidence.py --check-staged` |\n",
    "| Run tests | `uv run pytest tools/tests/test_check_evidence.py -v` |\n",
    "| Run tests + coverage | `uv run pytest tools/tests/test_check_evidence.py --cov=tools.scripts.check_evidence` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ad777",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "\n",
    "```bash\n",
    "# 1. Create evidence artifact\n",
    "# Copy from existing artifact or write from scratch\n",
    "\n",
    "# 2. Validate\n",
    "uv run tools/scripts/check_evidence.py --verbose\n",
    "\n",
    "# 3. Fix any reported issues in frontmatter, sections, or filename\n",
    "\n",
    "# 4. Commit\n",
    "git add architecture/evidence/\n",
    "git commit -m \"docs: Add analysis A-26002\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2ac82",
   "metadata": {},
   "source": [
    "### Key Files\n",
    "\n",
    "| File | Purpose |\n",
    "|------|---------|\n",
    "| `tools/scripts/check_evidence.py` | Main validation script |\n",
    "| `tools/tests/test_check_evidence.py` | Test suite (75 tests) |\n",
    "| `architecture/evidence/evidence.config.yaml` | SSoT for validation rules |\n",
    "| `architecture/architecture.config.yaml` | Parent config (shared tags) |\n",
    "| `pyproject.toml` | Config pointer (`[tool.check-evidence]`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532011fd",
   "metadata": {},
   "source": [
    "## **3. Key Capabilities & Logic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc91e3d",
   "metadata": {},
   "source": [
    "### A. Config Resolution Chain\n",
    "\n",
    "The script resolves its configuration through a two-level pointer chain:\n",
    "\n",
    "| Step | Source | Resolves |\n",
    "|------|--------|----------|\n",
    "| **1. pyproject.toml** | `[tool.check-evidence].config` | Relative path to `evidence.config.yaml` |\n",
    "| **2. evidence.config.yaml** | `parent_config` | Relative path to `architecture.config.yaml` |\n",
    "| **3. architecture.config.yaml** | `tags` | Shared architectural vocabulary |\n",
    "\n",
    "This allows the evidence config to inherit shared tags without duplication, following the ADR-26036 convention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a8a88",
   "metadata": {},
   "source": [
    "### B. Artifact Discovery\n",
    "\n",
    "The script discovers evidence artifacts by:\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| **Config scan** | Iterates over `artifact_types` keys in config |\n",
    "| **Directory resolution** | Each type's `directory_name` → subdirectory under `evidence/` |\n",
    "| **Pattern filter** | Filenames matched against `naming_patterns[type]` regex |\n",
    "| **Frontmatter parse** | YAML frontmatter extracted between `---` delimiters |\n",
    "| **Sort** | Artifacts returned sorted by `artifact_id` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df64c96",
   "metadata": {},
   "source": [
    "### C. Validation Rules\n",
    "\n",
    "**Frontmatter Errors:**\n",
    "\n",
    "| Error Type | Description |\n",
    "|------------|-------------|\n",
    "| `missing_field` | Required field missing (common or type-specific) |\n",
    "| `invalid_status` | Status not in allowed list from config |\n",
    "| `invalid_severity` | Severity not in allowed list from config |\n",
    "| `invalid_tag` | Tag not in parent config's tag vocabulary |\n",
    "| `invalid_date` | Date doesn't match YYYY-MM-DD format |\n",
    "\n",
    "**Naming Errors:**\n",
    "\n",
    "| Error Type | Description |\n",
    "|------------|-------------|\n",
    "| `naming` | Filename doesn't match regex pattern from config |\n",
    "\n",
    "**Section Errors:**\n",
    "\n",
    "| Error Type | Description |\n",
    "|------------|-------------|\n",
    "| `missing_section` | Required `##` section not found |\n",
    "| `unexpected_section` | `##` header not in required + optional whitelist |\n",
    "\n",
    "**Warnings:**\n",
    "\n",
    "| Warning Type | Description |\n",
    "|------------|-------------|\n",
    "| `orphan` | Source with null `extracted_into` older than `orphan_warning_days` threshold |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee9640",
   "metadata": {},
   "source": [
    "### D. Artifact Type Definitions\n",
    "\n",
    "Each artifact type in `evidence.config.yaml` specifies:\n",
    "\n",
    "| Field | Purpose |\n",
    "|-------|---------|\n",
    "| `directory_name` | Leaf directory under `evidence/` |\n",
    "| `id_prefix` | Namespace prefix (e.g., `A`, `R`, `S`) |\n",
    "| `required_fields` | Type-specific frontmatter fields |\n",
    "| `optional_fields` | Allowed but not required fields |\n",
    "| `statuses` | Valid lifecycle states (empty = no lifecycle) |\n",
    "| `required_sections` | Mandatory `##` headers |\n",
    "| `optional_sections` | Additional allowed `##` headers |\n",
    "\n",
    "The script computes:\n",
    "- `all_required_fields = common_required_fields + required_fields`\n",
    "- `all_allowed_sections = required_sections + optional_sections`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56492351",
   "metadata": {},
   "source": [
    "### E. Orphaned Source Detection\n",
    "\n",
    "Sources follow the three-commit workflow (ADR-26035 §5):\n",
    "1. Commit source to `evidence/sources/`\n",
    "2. Write analysis referencing source, update source's `extracted_into`\n",
    "3. Delete source file (git preserves it)\n",
    "\n",
    "The script detects sources that may have been forgotten:\n",
    "- `extracted_into` is null (not yet processed)\n",
    "- `date` is older than `lifecycle.orphan_warning_days` (default: 30 days)\n",
    "- These are reported as **warnings**, not errors (exit code stays 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdd557",
   "metadata": {},
   "source": [
    "## **4. Operational Guide**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb62f64",
   "metadata": {},
   "source": [
    "### CLI Options\n",
    "\n",
    "| Option | Description |\n",
    "|--------|-------------|\n",
    "| `--verbose` | Show detailed output including artifact names and counts |\n",
    "| `--check-staged` | Only validate files staged in git (for pre-commit delta mode) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0170a",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d77b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:06:47.300196Z",
     "iopub.status.busy": "2026-02-27T16:06:47.299807Z",
     "iopub.status.idle": "2026-02-27T16:06:47.406777Z",
     "shell.execute_reply": "2026-02-27T16:06:47.405550Z",
     "shell.execute_reply.started": "2026-02-27T16:06:47.300159Z"
    }
   },
   "outputs": [],
   "source": [
    "cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b43450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:06:49.184765Z",
     "iopub.status.busy": "2026-02-27T16:06:49.184371Z",
     "iopub.status.idle": "2026-02-27T16:06:49.512331Z",
     "shell.execute_reply": "2026-02-27T16:06:49.511015Z",
     "shell.execute_reply.started": "2026-02-27T16:06:49.184732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validate all evidence artifacts (default)\n",
    "env -u VIRTUAL_ENV uv run tools/scripts/check_evidence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e00439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:06:51.331514Z",
     "iopub.status.busy": "2026-02-27T16:06:51.331220Z",
     "iopub.status.idle": "2026-02-27T16:06:51.706752Z",
     "shell.execute_reply": "2026-02-27T16:06:51.705890Z",
     "shell.execute_reply.started": "2026-02-27T16:06:51.331490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validating A-26001 (analysis)\n",
      "\n",
      "Evidence validation: 1 artifacts checked\n",
      "  All artifacts valid.\n"
     ]
    }
   ],
   "source": [
    "# Verbose output\n",
    "env -u VIRTUAL_ENV uv run tools/scripts/check_evidence.py --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b13bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:06:53.849354Z",
     "iopub.status.busy": "2026-02-27T16:06:53.849075Z",
     "iopub.status.idle": "2026-02-27T16:06:54.247927Z",
     "shell.execute_reply": "2026-02-27T16:06:54.245514Z",
     "shell.execute_reply.started": "2026-02-27T16:06:53.849333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evidence validation: 0 artifacts checked\n",
      "  All artifacts valid.\n"
     ]
    }
   ],
   "source": [
    "# Check only staged files (for pre-commit)\n",
    "env -u VIRTUAL_ENV uv run tools/scripts/check_evidence.py --check-staged --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a7aad",
   "metadata": {},
   "source": [
    "### Exit Codes\n",
    "\n",
    "| Code | Meaning |\n",
    "|------|---------|\n",
    "| `0` | All evidence artifacts are valid (or none exist) |\n",
    "| `1` | One or more validation errors found |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062958ed",
   "metadata": {},
   "source": [
    "## **5. Validation Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d9bafb",
   "metadata": {},
   "source": [
    "### Pre-commit Hook\n",
    "\n",
    "The script runs automatically via pre-commit when evidence files change:\n",
    "\n",
    "```yaml\n",
    "- id: check-evidence\n",
    "  name: Validate evidence artifacts\n",
    "  entry: uv run --active tools/scripts/check_evidence.py --check-staged\n",
    "  language: system\n",
    "  pass_filenames: false\n",
    "  files: ^architecture/evidence/\n",
    "```\n",
    "\n",
    "A companion hook runs the test suite when the script or its tests change:\n",
    "\n",
    "```yaml\n",
    "- id: test-check-evidence\n",
    "  name: Test check_evidence\n",
    "  entry: uv run --active pytest tools/tests/test_check_evidence.py\n",
    "  language: system\n",
    "  pass_filenames: false\n",
    "  files: ^(tools/scripts/check_evidence\\.py|tools/tests/test_check_evidence\\.py|tools/scripts/paths\\.py|architecture/evidence/evidence\\.config\\.yaml)$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291f888",
   "metadata": {},
   "source": [
    "### GitHub Actions\n",
    "\n",
    "The script runs in CI via the `evidence-validation` job in `quality.yml`:\n",
    "\n",
    "```yaml\n",
    "evidence-validation:\n",
    "  runs-on: ubuntu-latest\n",
    "  steps:\n",
    "    - name: Run Evidence Validation\n",
    "      run: uv run tools/scripts/check_evidence.py --verbose\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbdd8f1",
   "metadata": {},
   "source": [
    "## **6. Test Suite**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb9083",
   "metadata": {},
   "source": [
    "The [test suite](/tools/tests/test_check_evidence.py) provides 75 tests with config-driven, non-brittle design:\n",
    "\n",
    "| Test Class | Coverage |\n",
    "|------------|----------|\n",
    "| `TestConfigLoading` | Config resolution from pyproject.toml, parent config tags, error handling |\n",
    "| `TestValidateNaming` | Valid/invalid filenames per type against regex patterns from config |\n",
    "| `TestValidateFrontmatter` | Required fields (common + type-specific), valid statuses, severity, tags, date format |\n",
    "| `TestValidateSections` | Required sections present, optional sections allowed, unexpected sections flagged, free-form types |\n",
    "| `TestDetectOrphanedSources` | Extracted sources not flagged, recent sources not flagged, old unextracted sources flagged |\n",
    "| `TestDiscoverArtifacts` | Per-type discovery, sorted by ID, empty directories, non-matching files ignored |\n",
    "| `TestCli` | Exit 0 on valid, exit 1 on errors, exit 0 on empty, --verbose and --check-staged flags |\n",
    "\n",
    "**Design principles:**\n",
    "- All constants derived from production configs (SSoT chain: `pyproject.toml` → `evidence.config.yaml` → `architecture.config.yaml`)\n",
    "- Single module import: `import tools.scripts.check_evidence as _module`\n",
    "- Heuristic field resolver (`_resolve_field_default`) generates valid test values without hardcoding field names\n",
    "- Semantic assertions: test contracts (exit codes, error presence) not message strings\n",
    "\n",
    "Run tests with:\n",
    "\n",
    "```bash\n",
    "uv run pytest tools/tests/test_check_evidence.py -v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b7ab8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:07:03.138773Z",
     "iopub.status.busy": "2026-02-27T16:07:03.138436Z",
     "iopub.status.idle": "2026-02-27T16:07:05.080064Z",
     "shell.execute_reply": "2026-02-27T16:07:05.078900Z",
     "shell.execute_reply.started": "2026-02-27T16:07:03.138742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 96%]\n",
      "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m75 passed\u001b[0m\u001b[32m in 1.24s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env -u VIRTUAL_ENV uv run pytest tools/tests/test_check_evidence.py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a765dabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T16:07:05.848561Z",
     "iopub.status.busy": "2026-02-27T16:07:05.847214Z",
     "iopub.status.idle": "2026-02-27T16:07:09.625116Z",
     "shell.execute_reply": "2026-02-27T16:07:09.622705Z",
     "shell.execute_reply.started": "2026-02-27T16:07:05.848510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 96%]\n",
      "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform linux, python 3.13.5-final-0 ________________\n",
      "\n",
      "Name                              Stmts   Miss  Cover   Missing\n",
      "---------------------------------------------------------------\n",
      "tools/scripts/check_evidence.py     217     24    89%   69-70, 88, 174-179, 209-211, 244-249, 398, 404, 408, 416-417, 453, 457, 504-505, 509\n",
      "---------------------------------------------------------------\n",
      "TOTAL                               217     24    89%\n",
      "\u001b[32m\u001b[32m\u001b[1m75 passed\u001b[0m\u001b[32m in 2.96s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env -u VIRTUAL_ENV uv run pytest tools/tests/test_check_evidence.py --cov=tools.scripts.check_evidence --cov-report=term-missing -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc52975",
   "metadata": {},
   "source": [
    "## **7. Common Scenarios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b63b8",
   "metadata": {},
   "source": [
    "### Scenario 1: Adding a New Analysis\n",
    "\n",
    "**Goal**: Create a new analysis and validate it.\n",
    "\n",
    "```bash\n",
    "# 1. Create the analysis file\n",
    "# Filename must match pattern: A-YYXXX_slug.md (e.g., A-26002_llm_evaluation.md)\n",
    "\n",
    "# 2. Add required frontmatter:\n",
    "# ---\n",
    "# id: A-26002\n",
    "# title: LLM Evaluation Framework\n",
    "# date: 2026-02-27\n",
    "# status: active\n",
    "# tags: [model]\n",
    "# ---\n",
    "\n",
    "# 3. Add required sections: Problem Statement, References\n",
    "# Add optional sections as needed: Approach Evaluation, Key Insights, etc.\n",
    "\n",
    "# 4. Validate\n",
    "uv run tools/scripts/check_evidence.py --verbose\n",
    "\n",
    "# 5. Stage and commit\n",
    "git add architecture/evidence/analyses/A-26002_llm_evaluation.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b75f71",
   "metadata": {},
   "source": [
    "### Scenario 2: Adding a Retrospective\n",
    "\n",
    "**Goal**: Document a post-mortem or failure analysis.\n",
    "\n",
    "```bash\n",
    "# 1. Create the retrospective file\n",
    "# Filename: R-YYXXX_slug.md (e.g., R-26001_deployment_failure.md)\n",
    "\n",
    "# 2. Required frontmatter includes severity:\n",
    "# ---\n",
    "# id: R-26001\n",
    "# title: Deployment Failure Analysis\n",
    "# date: 2026-02-27\n",
    "# status: active\n",
    "# severity: high\n",
    "# tags: [devops]\n",
    "# ---\n",
    "\n",
    "# 3. Required sections: Executive Summary, References\n",
    "\n",
    "# 4. Validate and commit\n",
    "uv run tools/scripts/check_evidence.py --verbose\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e53136",
   "metadata": {},
   "source": [
    "### Scenario 3: Processing a Source (Three-Commit Workflow)\n",
    "\n",
    "**Goal**: Capture a dialogue transcript and extract insights.\n",
    "\n",
    "```bash\n",
    "# Commit 1: Add source\n",
    "git add architecture/evidence/sources/S-26001_claude_discussion.md\n",
    "git commit -m \"docs: Add source S-26001\"\n",
    "\n",
    "# Commit 2: Write analysis, update source's extracted_into\n",
    "# In S-26001: set extracted_into: A-26002\n",
    "# Create A-26002_insights.md referencing the source\n",
    "git add architecture/evidence/\n",
    "git commit -m \"docs: Add analysis A-26002 from source S-26001\"\n",
    "\n",
    "# Commit 3: Delete source (git preserves history)\n",
    "git rm architecture/evidence/sources/S-26001_claude_discussion.md\n",
    "git commit -m \"chore: Remove processed source S-26001\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0dc29",
   "metadata": {},
   "source": [
    "### Scenario 4: Adding a New Tag\n",
    "\n",
    "**Goal**: Use a tag that's not in the shared vocabulary.\n",
    "\n",
    "```bash\n",
    "# 1. Validation shows invalid tag\n",
    "uv run tools/scripts/check_evidence.py --verbose\n",
    "# Output: Invalid tags: ['new_tag'] (valid: [...])\n",
    "\n",
    "# 2. Add the tag to the parent config\n",
    "# Edit architecture/architecture.config.yaml:\n",
    "# tags:\n",
    "#   - ...\n",
    "#   - new_tag\n",
    "\n",
    "# 3. Re-validate\n",
    "uv run tools/scripts/check_evidence.py --verbose\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25bef7f",
   "metadata": {},
   "source": [
    "### Scenario 5: Pre-commit Validation\n",
    "\n",
    "**Goal**: Validate evidence before committing.\n",
    "\n",
    "```bash\n",
    "# The pre-commit hook runs automatically when evidence files change\n",
    "git add architecture/evidence/analyses/A-26002_new_analysis.md\n",
    "git commit -m \"docs: Add analysis A-26002\"\n",
    "\n",
    "# If validation fails:\n",
    "# Validate evidence artifacts...Failed\n",
    "# Fix the reported issues and retry\n",
    "\n",
    "# For staged-only validation (faster):\n",
    "uv run tools/scripts/check_evidence.py --check-staged --verbose\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
