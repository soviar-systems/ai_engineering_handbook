{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366dbb30-972b-49c3-9180-fb5ea4ba920b",
   "metadata": {},
   "source": [
    "# Aider Commands Handout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33dd3d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Owner: Vadim Rudakov, lefthand67@gmail.com  \n",
    "Version: 0.1.3  \n",
    "Birth: 2025-11-18  \n",
    "Last Modified: 2026-01-10\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcaf987",
   "metadata": {},
   "source": [
    "Aider is an AI pair programmer that uses your code as context.\n",
    "\n",
    ":::{seealso} How to set up aider\n",
    "> [VIM in AI Era: Hybrid Setup with Ollama and Aider](/tools/docs/ai_agents/01_vim_in_ai_era_hybrid_setup_with_ollama_and_aider.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e36c94",
   "metadata": {},
   "source": [
    "## **1. Installation and Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ab282",
   "metadata": {},
   "source": [
    "command|description\n",
    "-|-\n",
    "**Installation**|\n",
    "`uv tool install aider-chat`|install aider with uv (faster)\n",
    "`pipx install aider-chat`|install aider with pipx (traditional way)\n",
    "`uv tool install aider-chat[browser]`|install browser extension (experimental feature)\n",
    "`aider -h`|show help message and exit\n",
    "`aider --version`|Show the version number and exit\n",
    "**Configuration files**|\n",
    "`/path/to/project/.aider.conf.yml`|poject level file\n",
    "`$HOME/.aider.conf.yml`|user level file\n",
    "`-c /path/to/.aider.conf.yml`|specific file, i.e. project level\n",
    "**Essential Configuration Flags**|\n",
    "`--model MODEL`|Specify the LLM to use\n",
    "`--light-mode`|Use colors suitable for a light terminal background (default: False), env var: `AIDER_LIGHT_MODE`\n",
    "`--auto-commits`, `--no-auto-commits`|Enable/disable auto commit of LLM changes (default: True) env var: `AIDER_AUTO_COMMITS`\n",
    "\n",
    "Args that start with `--` can be set in a config file. The config file uses YAML syntax and must represent a YAML 'mapping' (for details, see http://learn.getgrav.org/advanced/yaml). \n",
    "\n",
    ":::{important} **Precedence**\n",
    "In general, command-line values override environment variables which override config file values which override defaults.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf17389-0553-4119-97ba-f425e3631f3e",
   "metadata": {},
   "source": [
    ":::{tip} Basic configuration in file\n",
    ":class: dropdown\n",
    "Reepository config file example: `/.aider.conf.yml`\n",
    "\n",
    "```yaml\n",
    "# Disable telemetry to keep your usage data private\n",
    "analytics-disable: true\n",
    "\n",
    "# Automatically load these files as read-only context for every session\n",
    "# Great for project-specific coding standards or documentation\n",
    "read:\n",
    "  - aider.CONVENTIONS\n",
    "\n",
    "# --- Global Interface & Git Options ---------\n",
    "\n",
    "# Set the language used for AI-generated commit messages\n",
    "commit-language: \"US English\"\n",
    "\n",
    "# Specify your preferred CLI text editor for long-form input\n",
    "editor: \"vim\"\n",
    "\n",
    "# Optimized for terminal themes with light backgrounds\n",
    "light-mode: true\n",
    "\n",
    "# Set to 'false' to review changes before Aider commits them to Git\n",
    "auto-commits: false\n",
    "\n",
    "# Hide technical warnings about specific model quirks\n",
    "show-model-warnings: false\n",
    "\n",
    "# Max tokens to use for the 'repo map' (helps the AI understand project structure)\n",
    "map-tokens: 2048\n",
    "\n",
    "# ----- Model Selection -----------\n",
    "\n",
    "# The primary model used for the chat interface\n",
    "model: gemini/gemini-2.5-flash\n",
    "\n",
    "# A secondary model used specifically for applying code edits \n",
    "# (useful for saving costs or using a local model for logic)\n",
    "editor-model: ollama_chat/qwen2.5-coder:14b-instruct-q4_K_M\n",
    "\n",
    "# Friendly names for switching models quickly within the chat\n",
    "alias:\n",
    "  - \"qwen14:ollama_chat/qwen2.5-coder:14b-instruct-q4_K_M\"\n",
    "  - \"gemini2.5-flash:gemini/gemini-2.5-flash\"\n",
    "\n",
    "# ----- Authentication -----------\n",
    "\n",
    "# Provide API keys for cloud providers\n",
    "api-key:\n",
    "  - gemini=<your_api_key>\n",
    "\n",
    "# ---- Environment Configuration ----------\n",
    "\n",
    "# Define system variables, such as the local endpoint for Ollama\n",
    "set-env:\n",
    "  - OLLAMA_API_BASE=http://localhost:11434\n",
    "\n",
    "```\n",
    "\n",
    "**Starting the Session**\n",
    "\n",
    "When you run `aider` from your terminal, the output confirms that the configuration was loaded correctly:\n",
    "\n",
    "```bash\n",
    "$ aider\n",
    "Analytics have been permanently disabled.\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "Aider v0.86.1\n",
    "Model: gemini/gemini-2.5-flash with diff-fenced edit format\n",
    "Git repo: .git with 243 files\n",
    "Repo-map: using 2048 tokens, auto refresh\n",
    "Added aider.CONVENTIONS to the chat (read-only).\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "Readonly: aider.CONVENTIONS\n",
    "> \n",
    "\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d0b96-c6ec-414e-8ee2-dadc4fcbb0d0",
   "metadata": {},
   "source": [
    "## **2. Using proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9cec1-f600-42a3-b704-a4cce14410cc",
   "metadata": {},
   "source": [
    "If your organization requires all external traffic to be routed through the proxy, you can set these environment variables and pass them to the terminal session before starting the aider:\n",
    "\n",
    "```bash\n",
    "export HTTPS_PROXY=\"http://[user:password]@proxy_ip_address:port\"\n",
    "export https_proxy=\"http://[user:password]@proxy_ip_address:port\"\n",
    "```\n",
    "\n",
    "You should NOT set `HTTP_PROXY` variable because it breaks the connection between the aider and local ollama through `http://127.0.0.1:11434`.\n",
    "\n",
    "You can wrap this configuration into a script wrapper `aider_proxy.sh`:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -euo pipefail\n",
    "\n",
    "\n",
    "main() {\n",
    "\n",
    "    export HTTPS_PROXY=\"http://[user:password]@proxy_ip_address:port\"\n",
    "    export https_proxy=\"http://[user:password]@proxy_ip_address:port\"\n",
    "\n",
    "    exec aider \"$@\"\n",
    "}\n",
    "\n",
    "\n",
    "main \"$@\"\n",
    "```\n",
    "\n",
    "Make this [script executable](/tools/docs/scripts_instructions/how_to_use_scripts_on_gnu_linux.ipynb) and add it to your PATH. Now you can run aider simply:\n",
    "\n",
    "```bash\n",
    "$ aider_proxy.sh --model gemini/gemini-3-flash\n",
    "```\n",
    "\n",
    "Avoid using proxy if it's not necessary for it adds complexity to the aider configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47094a2a",
   "metadata": {},
   "source": [
    "## **3. Running & Basic Usage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a884cb9",
   "metadata": {},
   "source": [
    "### Launching aider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ec38a",
   "metadata": {},
   "source": [
    "command|description\n",
    "-|-\n",
    "`aider --model ollama_chat/<model_name>`|run a local model in terminal (get name from `ollama ls`)\n",
    "`--gui`, `--no-gui`, `--browser`, `--no-browser`|Run aider in your browser (default: False); env var: `AIDER_GUI`\n",
    "`aider --list-models gemini/`| list available models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2751fbf",
   "metadata": {},
   "source": [
    "### Core File Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b49c1",
   "metadata": {},
   "source": [
    "| Command | Description |\n",
    "| :--- | :--- |\n",
    "`--file FILE`|specify a file to edit (can be used multiple times); env var: `AIDER_FILE`\n",
    "`--read FILE`|specify a read-only file (can be used multiple times); env var: `AIDER_READ`\n",
    "`/add`|Add files to the chat so aider can edit them or review them in detail.\n",
    "`/tokens`|Report on the number of tokens used by the current chat context\n",
    "\n",
    ":::{tip}\n",
    "Use `/add` to tell Aider a file exists and is available for modification. This way aider knows this file exists and **will write to it**. Otherwise, aider might write the changes to an existing file; [source](https://aider.chat/docs/usage/tips.html)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea92bf7",
   "metadata": {},
   "source": [
    "### Using the Repository Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa3dd9",
   "metadata": {},
   "source": [
    "command|description\n",
    "| :--- | :--- |\n",
    "| `--map-tokens NUM` | **Limit the size** of the Repository Map in tokens (e.g., `aider --map-tokens 500`). |\n",
    "| `/map` | **Display** the current Repository Map summary. |\n",
    "\n",
    "The **Repository Map** provides a structural overview (file/function) of your project, helping the AI understand context without loading the entire codebase, thus saving tokens. Use `--map-tokens` to manage this resource (default is 1024 tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b222e4c",
   "metadata": {},
   "source": [
    "### In-Chat Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa28d6",
   "metadata": {},
   "source": [
    "command|description\n",
    "| :--- | :--- |\n",
    "| `/help` | Ask questions about Aider's features and usage. Aider's help is context-aware, i.e. it can answer questions about itself.|\n",
    "| `/clear` | **Clear the chat history** (saves tokens). |\n",
    "| `/run COMMAND` | Run an **arbitrary shell command** and share the output with the LLM. |\n",
    "| `/undo` | **Undo the last Git commit** (only works for Aider's auto-commits). |\n",
    "| `/web URL` | **Scrape a webpage**, convert to markdown and send in a message. |\n",
    "| `/diff` | Show the **difference** between the current files and the last Aider commit. |\n",
    "| `/commit MESSAGE` | Manually commit the current changes with a specific message. |\n",
    "| `/exit` or `/quit` | Exit Aider. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecc301-3bc8-4baf-a485-b00d1367e492",
   "metadata": {},
   "source": [
    "## **4. Aider Integration with LLMs Using API Keys**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88422cbf-7319-46f6-8278-cf6846221c1c",
   "metadata": {},
   "source": [
    "Connect your aider to the capable LLMs, like Gemini, Grok, etc. with the free or paid teer. This allows you to work with much bigger context windows than the local LMs provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0d533-d214-46fd-b582-c767f67b7df6",
   "metadata": {},
   "source": [
    "### 4.1 Obtain an API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1593f-5405-45b7-919f-e6ed574f3854",
   "metadata": {},
   "source": [
    "#### Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf251fc-f4dd-4939-81e2-62d507f12ec6",
   "metadata": {},
   "source": [
    "Get it in the [Google AI studio](https://aistudio.google.com/api-keys), free tier is enough for start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff31e4-66bd-45a7-8187-e5413767c634",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "> [Gemini API quickstart](https://ai.google.dev/gemini-api/docs/quickstart)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce262d39-7338-4fcf-9d73-73ad28c51a97",
   "metadata": {},
   "source": [
    "### 4.2 Add API to aider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c4327-9eb3-4717-ae7c-abf1f421ef29",
   "metadata": {},
   "source": [
    "You can pass an API key using either the command line or the config file: \n",
    "\n",
    "```bash\n",
    "$ aider --model gemini/gemini-2.5-flash --api-key gemini=<your_api_key>\n",
    "```\n",
    "\n",
    "Using your LOCAL `~/.aider.conf.yml`. Set Gemini as the main (architect) model and save the API key:\n",
    "\n",
    "```bash\n",
    "$ ~/.aider.conf.yml\n",
    "\n",
    "model: gemini/gemini-2.5-flash\n",
    "\n",
    "api-key:\n",
    "  - gemini=<your_api_key>\n",
    "```\n",
    "\n",
    "Now you can launch it like this:\n",
    "\n",
    "```bash\n",
    "$ aider\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bfbb5-e25c-4792-813c-d6b9eebf89c5",
   "metadata": {},
   "source": [
    "#### Gemini limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385e338-ac6f-443f-a03c-75d83e1d4b24",
   "metadata": {},
   "source": [
    "But it is a better idea to choose a model via command line because each Gemini model you request has its own limit. You can control the usage [here](https://aistudio.google.com/app/usage):\n",
    "\n",
    ":::{important} How rate limits work\n",
    ":class: dropdown\n",
    "Rate limits are usually measured across three dimensions:\n",
    "\n",
    "Requests per minute (RPM)\n",
    "Tokens per minute (input) (TPM)\n",
    "Requests per day (RPD)\n",
    "Your usage is evaluated against each limit, and exceeding any of them will trigger a rate limit error. For example, if your RPM limit is 20, making 21 requests within a minute will result in an error, even if you haven't exceeded your TPM or other limits.\n",
    "\n",
    "Rate limits are applied per project, not per API key. Requests per day (RPD) quotas reset at midnight Pacific time.\n",
    "> --- [Gemini API: Rate limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "```{figure} ./images/gemini_limits_free_tier.png\n",
    "Free tier rate limits by model. Peak usage per model compared to its limit over the last 28 days\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5cabb-22a2-4fb2-8978-fff506af9010",
   "metadata": {},
   "source": [
    "### 4.3 Switch between models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d312d6c-8f91-432c-8728-43f4587fc9e7",
   "metadata": {},
   "source": [
    "The capable LLM will act as the main model to help you prepare the plan based on the large context while the local model set as `editor-model` will do the coding, testing, and fixing, saving you tokens.\n",
    "\n",
    "Edit your local, NOT the repo's `.aider.conf.yml`:\n",
    "\n",
    "```bash\n",
    "$ ~/.aider.conf.yml\n",
    "\n",
    "editor-model: ollama_chat/qwen2.5-coder:14b-instruct-q4_K_M\n",
    "```\n",
    "\n",
    "Now in the `/architect` mode the Gemini model will send tasks to the local Qwen model on your local GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b075de-1dae-4b56-ad32-51cbcea9127d",
   "metadata": {},
   "source": [
    "Here is the comprehensive list of available Gemini models through aider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3431d6b-72ee-4f50-93f0-3e3676dfe8d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T18:31:50.693381Z",
     "iopub.status.busy": "2026-01-10T18:31:50.693184Z",
     "iopub.status.idle": "2026-01-10T18:31:53.647374Z",
     "shell.execute_reply": "2026-01-10T18:31:53.646808Z",
     "shell.execute_reply.started": "2026-01-10T18:31:50.693364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics have been permanently disabled.\n",
      "\u001b[?12l\u001b[?25h\u001b[32m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "Models which match \"gemini/\":\n",
      "- gemini/gemini-1.5-flash\n",
      "- gemini/gemini-1.5-flash-001\n",
      "- gemini/gemini-1.5-flash-002\n",
      "- gemini/gemini-1.5-flash-8b\n",
      "- gemini/gemini-1.5-flash-8b-exp-0827\n",
      "- gemini/gemini-1.5-flash-8b-exp-0924\n",
      "- gemini/gemini-1.5-flash-exp-0827\n",
      "- gemini/gemini-1.5-flash-latest\n",
      "- gemini/gemini-1.5-pro\n",
      "- gemini/gemini-1.5-pro-001\n",
      "- gemini/gemini-1.5-pro-002\n",
      "- gemini/gemini-1.5-pro-exp-0801\n",
      "- gemini/gemini-1.5-pro-exp-0827\n",
      "- gemini/gemini-1.5-pro-latest\n",
      "- gemini/gemini-2.0-flash\n",
      "- gemini/gemini-2.0-flash-001\n",
      "- gemini/gemini-2.0-flash-exp\n",
      "- gemini/gemini-2.0-flash-lite\n",
      "- gemini/gemini-2.0-flash-lite-preview-02-05\n",
      "- gemini/gemini-2.0-flash-live-001\n",
      "- gemini/gemini-2.0-flash-preview-image-generation\n",
      "- gemini/gemini-2.0-flash-thinking-exp\n",
      "- gemini/gemini-2.0-flash-thinking-exp-01-21\n",
      "- gemini/gemini-2.0-pro-exp-02-05\n",
      "- gemini/gemini-2.5-computer-use-preview-10-2025\n",
      "- gemini/gemini-2.5-flash\n",
      "- gemini/gemini-2.5-flash-lite\n",
      "- gemini/gemini-2.5-flash-lite-preview-06-17\n",
      "- gemini/gemini-2.5-flash-lite-preview-09-2025\n",
      "- gemini/gemini-2.5-flash-preview-04-17\n",
      "- gemini/gemini-2.5-flash-preview-05-20\n",
      "- gemini/gemini-2.5-flash-preview-09-2025\n",
      "- gemini/gemini-2.5-flash-preview-tts\n",
      "- gemini/gemini-2.5-pro\n",
      "- gemini/gemini-2.5-pro-exp-03-25\n",
      "- gemini/gemini-2.5-pro-preview-03-25\n",
      "- gemini/gemini-2.5-pro-preview-05-06\n",
      "- gemini/gemini-2.5-pro-preview-06-05\n",
      "- gemini/gemini-2.5-pro-preview-tts\n",
      "- gemini/gemini-3-flash-preview\n",
      "- gemini/gemini-3-pro-preview\n",
      "- gemini/gemini-exp-1114\n",
      "- gemini/gemini-exp-1206\n",
      "- gemini/gemini-flash-latest\n",
      "- gemini/gemini-flash-lite-latest\n",
      "- gemini/gemini-gemma-2-27b-it\n",
      "- gemini/gemini-gemma-2-9b-it\n",
      "- gemini/gemini-live-2.5-flash-preview-native-audio-09-2025\n",
      "- gemini/gemini-pro\n",
      "- gemini/gemini-pro-vision\n",
      "- gemini/gemma-3-27b-it\n",
      "- gemini/learnlm-1.5-pro-experimental\n"
     ]
    }
   ],
   "source": [
    "aider_proxy.sh --list-models gemini/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a062d4",
   "metadata": {},
   "source": [
    "## **5. Upgrading**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f5410-724f-49e5-ae22-b745f853f1d4",
   "metadata": {},
   "source": [
    "command|description\n",
    "| :--- | :--- |\n",
    "`uv tool --upgrade aider-chat aider-chat[browser]`||\n",
    "`aider --install-main-branch`|Install the latest version from the main branch; env var: `AIDER_INSTALL_MAIN_BRANCH`. Use for beta features only.\n",
    "`aider --upgrade, --update`|Upgrade aider to the latest version from PyPI; env var: `AIDER_UPGRADE`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
