{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11efec7-7a70-4532-b93d-48917052667e",
   "metadata": {},
   "source": [
    "# vim-ollama: LLM Tab Completion Nuances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898714e-3c55-47aa-bd28-f071b45c3a4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Owner: Vadim Rudakov, lefthand67@gmail.com  \n",
    "Version: 0.1.0  \n",
    "Birth: 2026-01-13  \n",
    "Last Modified: 2026-01-13\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605473e0-0ecc-4554-bb83-bdc7887c34f8",
   "metadata": {},
   "source": [
    "This handbook explains the mechanics of LLM-based tab completion within Vim specifically for the `vim-ollama` plugin and why specific model-config alignment is required for it to function correctly.\n",
    "\n",
    ":::{seealso}\n",
    "> Setup vim-ollama: [\"VIM in AI Era: Hybrid Setup with Ollama and Aider\"](/tools/docs/ai_agents/01_vim_in_ai_era_hybrid_setup_with_ollama_and_aider.ipynb)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c68840-6de4-4874-9fd8-849e61198624",
   "metadata": {},
   "source": [
    "## **Understanding the Model-to-Config Relationship**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e8c58-4010-48da-b431-3405c3e11c64",
   "metadata": {},
   "source": [
    "### 1. The Core Logic: FIM (Fill-In-the-Middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049431d4-072b-4307-9a8e-2552f748c785",
   "metadata": {},
   "source": [
    "Unlike a standard chat interface, tab completion uses a technique called **FIM**. For the model to provide a seamless completion, it must receive the code surrounding your cursor in a very specific format:\n",
    "\n",
    "* **Prefix:** Everything before the cursor.\n",
    "* **Suffix:** Everything after the cursor.\n",
    "* **Sentinels:** Special tokens (e.g., `<|fim_prefix|>`, `<|fim_suffix|>`) that tell the model where the gap is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36fa8ec3-4c47-4c12-8e25-b21436cc4d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T14:55:41.764834Z",
     "iopub.status.busy": "2026-01-13T14:55:41.764633Z",
     "iopub.status.idle": "2026-01-13T14:55:41.876655Z",
     "shell.execute_reply": "2026-01-13T14:55:41.876027Z",
     "shell.execute_reply.started": "2026-01-13T14:55:41.764809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pre\": \"<|fim_prefix|>\",\n",
      "    \"middle\": \"<|fim_middle|>\",\n",
      "    \"suffix\": \"<|fim_suffix|>\",\n",
      "    \"eot\": \"<|endoftext|>\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat ~/.vim/plugged/vim-ollama/python/configs/qwen3-coder.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f423d17-ba70-44e3-a158-d47ef862344e",
   "metadata": {},
   "source": [
    "### 2. The Role of JSON Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecaacf-75c8-4c98-a3db-99f999942b3b",
   "metadata": {},
   "source": [
    "In `vim-ollama`, the files located in `~/.vim/plugged/vim-ollama/python/configs/` act as **translation layers**.\n",
    "\n",
    "If you set `g:ollama_model = 'qwen3:4b-instruct'` in your `~/.vim/config/ollama.vim` which sets the tab completion model, the plugin searches these JSON files to find a matching template. If no match is found:\n",
    "\n",
    "1. The plugin may fail to send the correct \"Sentinel\" tokens.\n",
    "2. The model will receive raw text and likely try to \"continue\" the file as a chat or a blog post rather than completing the logic.\n",
    "3. You will often see empty suggestions or \"prose\" comments appearing in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c7393-a237-444c-8cdc-e72ef845788e",
   "metadata": {},
   "source": [
    "### 3. Coder vs. Instruct Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad0b7a-d779-406a-afe5-aa7dfcab147a",
   "metadata": {},
   "source": [
    "| Model Type | Purpose | Behavior in Tab Completion |\n",
    "| --- | --- | --- |\n",
    "| **Coder** | Trained on raw code & FIM patterns. | **Best.** Understands the gap between prefix and suffix. |\n",
    "| **Instruct** | Trained to follow conversational prompts. | **Poor.** Often tries to \"explain\" the code or chat with the user. |\n",
    "\n",
    ":::{important} **The Golden Rule**\n",
    "For Tab Completion to work, your `g:ollama_model` name must have a corresponding configuration file that defines its specific FIM tokens.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68759283-0f88-4347-a2bf-83893fe25139",
   "metadata": {},
   "source": [
    "## **Troubleshooting & Best Practices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6948a1-4948-4906-b935-35fb5b5c9017",
   "metadata": {},
   "source": [
    "### Scenario: \"I have the model, but completion isn't working\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0589c-1371-4ec9-b68d-a08bac475907",
   "metadata": {},
   "source": [
    "* **Check the Filename:** Ensure the string in your `.vimrc` matches the prefix of a JSON file in the `configs/` directory.\n",
    "* **Check the Model Type:** If you are using an `instruct` model for completion, the plugin may not have a template for it because instruct models generally do not support FIM tokens natively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e85356-7619-4536-ae0e-d6809fbf4e26",
   "metadata": {},
   "source": [
    "### Recommended Team Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b965a-db4b-41a9-bcb6-718fac59e70a",
   "metadata": {},
   "source": [
    "To ensure consistency across the team, everyone should use a model that has a verified config file:\n",
    "\n",
    "```vim\n",
    "\" In .vimrc\n",
    "\" Use a 'coder' variant for specialized FIM support\n",
    "let g:ollama_model = 'qwen2.5-coder:7b' \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca2078-2416-4c81-aa52-26afb1c217a0",
   "metadata": {},
   "source": [
    "### How to Add a New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea45d87-97e8-494e-9e57-e03d4e01ead6",
   "metadata": {},
   "source": [
    "If the team moves to a new model (e.g., `qwen3`) that isn't yet supported:\n",
    "\n",
    "1. Identify the model's FIM tokens from its official documentation.\n",
    "2. Create a new JSON file in `.../python/configs/` (e.g., `qwen3-coder.json`).\n",
    "3. Define the `prefix`, `suffix`, and `middle` tokens within that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b538a2-fcdd-454c-a989-6e1567f84328",
   "metadata": {},
   "source": [
    "## **Summary for the Team**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b9459-e372-4747-a812-e889d9c2b462",
   "metadata": {},
   "source": [
    "* **Tab completion is not \"plug and play\"** for every model.\n",
    "* **Consistency matters:** The model name in Vim must match a JSON config.\n",
    "* **Model Choice:** Always prefer `-coder` models over `-instruct` models for the `g:ollama_model` variable used for completion."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
