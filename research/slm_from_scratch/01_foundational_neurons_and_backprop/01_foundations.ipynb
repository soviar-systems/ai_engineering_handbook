{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f343e7",
   "metadata": {},
   "source": [
    "# PHASE 1: FOUNDATIONAL NEURONS & BACKPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c25bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T10:53:39.105167Z",
     "iopub.status.busy": "2025-12-29T10:53:39.104966Z",
     "iopub.status.idle": "2025-12-29T10:53:39.109452Z",
     "shell.execute_reply": "2025-12-29T10:53:39.109227Z",
     "shell.execute_reply.started": "2025-12-29T10:53:39.105146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.14.0 free-threading build (main, Oct 28 2025, 12:10:48) [Clang 20.1.4 ]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70419e",
   "metadata": {},
   "source": [
    "# Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db479a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# bash\n",
    "venv_name=\"slm_from_scratch\"\n",
    "venv_path=\"${HOME}/venv/${venv_name}\"\n",
    "\n",
    "create_jupyter_venv -p 3.14t -n \"${venv_name}\"\n",
    "\n",
    "uv pip install -p \"${venv_path}\" \\\n",
    "    matplotlib \\\n",
    "    numpy \\\n",
    "    seaborn\n",
    "\n",
    "# remove_jupyter_venv \"${venv_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af6dc6",
   "metadata": {},
   "source": [
    "**The Core Idea**: A neural network is just a mathematical function that can be represented as a computational graph. The \"learning\" happens by adjusting the parameters of this function to minimize some error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c20b0",
   "metadata": {},
   "source": [
    "# **1. Forward Pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b32048",
   "metadata": {},
   "source": [
    "We begin with the absolute building block of all deep learning: **the single neuron**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e83b14",
   "metadata": {},
   "source": [
    "# 1.1 The Mathematical Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833eea6",
   "metadata": {},
   "source": [
    "A neuron computes:\n",
    "\n",
    "```{math}\n",
    "z = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label: eq:activation_general\n",
    "a = \\sigma(z)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{x} \\in \\mathbb{R}^d$ is the input vector,\n",
    "- $\\mathbf{w} \\in \\mathbb{R}^d$ is the weight vector,\n",
    "- $b \\in \\mathbb{R}$ is the bias,\n",
    "- $\\sigma$ is a nonlinear activation function (e.g., ReLU, tanh),\n",
    "- $a$ is the output (activation).\n",
    "\n",
    "This is **not** a biological metaphor‚Äîit is a differentiable function that enables composition and gradient flow.\n",
    "\n",
    "\n",
    "```{mermaid}\n",
    "graph LR\n",
    "    X --> mul\n",
    "    W.T --> mul\n",
    "    b --> add\n",
    "    mul --> add\n",
    "    add --> z\n",
    "```\n",
    "\n",
    "Think about processing one input vector vs many inputs:\n",
    "\n",
    "**Single input**: $[x_1, x_2, x_3]$ with weights $[\\theta_1, \\theta_2, \\theta_3]$  \n",
    "$\\text {output} = x_1\\theta_1 + x_2\\theta_2 + x_3\\theta_3 + b$\n",
    "\n",
    "**Multiple inputs (as matrix)**: \n",
    "```\n",
    "Inputs: [ [x‚ÇÅ‚ÇÅ, x‚ÇÅ‚ÇÇ, x‚ÇÅ‚ÇÉ],   Weights: [ùúÉ‚ÇÅ, ùúÉ‚ÇÇ, ùúÉ‚ÇÉ]·µÄ\n",
    "          [x‚ÇÇ‚ÇÅ, x‚ÇÇ‚ÇÇ, x‚ÇÇ‚ÇÉ],\n",
    "          [x‚ÇÉ‚ÇÅ, x‚ÇÉ‚ÇÇ, x‚ÇÉ‚ÇÉ] ]\n",
    "```\n",
    "\n",
    "What linear algebra operation would efficiently compute all outputs at once? Matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b44cc8",
   "metadata": {},
   "source": [
    "Read about GEMM and BLAS:\n",
    "\n",
    "1. [*Matrix Multiplication Background User's Guide*](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html) - NVIDIA\n",
    "2. [*GEMM: The Engineering Standard*](../../../1_execution/algebra_gemm_engineering_standard.md) - SovIAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d67be",
   "metadata": {},
   "source": [
    "# 1.3 Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391d76d",
   "metadata": {},
   "source": [
    "Now, consider this:  \n",
    "**Why do we require $\\sigma$ in {eq}`eq:activation_general` to be nonlinear? What happens to the representational capacity of a multi-layer network if $\\sigma$ is linear?**\n",
    "\n",
    "Correct. If all activations are linear, the composition of layers collapses to a single linear transformation:  \n",
    "```{math}\n",
    "f(\\mathbf{x}) = \\mathbf{W}_L \\cdots \\mathbf{W}_2 \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_{\\text{total}} = \\mathbf{W}_{\\text{eff}} \\mathbf{x} + \\mathbf{b}_{\\text{eff}}\n",
    "```\n",
    "\n",
    "This cannot model nonlinear decision boundaries‚Äîhence the necessity of nonlinear $\\sigma$.\n",
    "\n",
    "```{hint} What is ‚Äúeff‚Äù in $\\mathbf{W}_{\\text{eff}}$?*\n",
    ":class: dropdown\n",
    "‚Äúeff‚Äù stands for **effective**. It denotes that the product of multiple weight matrices collapses to a **single equivalent linear transformation** when all activations are linear. So $\\mathbf{W}_{\\text{eff}} = \\mathbf{W}_L \\cdots \\mathbf{W}_1$ is the *effective weight matrix* of the entire network.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a20362",
   "metadata": {},
   "source": [
    "## Activation Function Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da0906",
   "metadata": {},
   "source": [
    "| Function | Formula | Range | Key Properties |\n",
    "|----------|---------|-------|----------------|\n",
    "| **Sigmoid** | 1/(1+e‚ÅªÀ£) | (0,1) | Smooth, bounded, but can saturate (vanishing gradients) |\n",
    "| **Tanh** | (eÀ£-e‚ÅªÀ£)/(eÀ£+e‚ÅªÀ£) | (-1,1) | Zero-centered, but still can saturate |\n",
    "| **ReLU** | max(0,x) | [0,‚àû) | Simple, avoids saturation, but \"dying ReLU\" problem |\n",
    "| **Leaky ReLU** | max(0.01x,x) | (-‚àû,‚àû) | Fixes dying ReLU, small gradient for negatives |\n",
    "\n",
    "**Historical Context & Modern Practice**\n",
    "\n",
    "- **1980s-2000s**: Sigmoid/tanh were dominant (biological plausibility)\n",
    "- **2010s**: ReLU became standard for hidden layers (training speed)\n",
    "- **Today**: Variants like Leaky ReLU, GELU are common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b637ad",
   "metadata": {},
   "source": [
    "### tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20c676",
   "metadata": {},
   "source": [
    "The hyperbolic tangent function is defined as:\n",
    "\n",
    "```{math}\n",
    "\\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\n",
    "```\n",
    "\n",
    "This is the **complete closed-form formula**. It maps $z \\in \\mathbb{R}$ to $a \\in (-1, 1)$.\n",
    "\n",
    "For computation by hand, you can evaluate it numerically using known values or a calculator.\n",
    "\n",
    "This is how the function looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tanh():\n",
    "    # Generate x values from -10 to 10\n",
    "    x = np.linspace(-10, 10, 400)\n",
    "    \n",
    "    # Compute tanh for each x value\n",
    "    y = np.tanh(x)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y, label='tanh(x)')\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title('Hyperbolic Tangent Function')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('tanh(x)')\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='black',linewidth=0.5)\n",
    "    plt.axvline(0, color='black',linewidth=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "# Call the function to display the plot\n",
    "plot_tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fa90e",
   "metadata": {},
   "source": [
    "# 1.4 What the Single Neuron really is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806048d",
   "metadata": {},
   "source": [
    "You already have **prior experience** (CNNs, NumPy backprop), so we are not teaching you deep learning from absolute zero. Instead, we are **recalibrating your foundation at the level required for an AI Architect**, where every operation must be understood in three layers simultaneously:\n",
    "\n",
    "1. **Mathematical identity** (e.g., chain rule, matrix derivatives),\n",
    "2. **Computational implementation** (e.g., NumPy/PyTorch code),\n",
    "3. **Hardware implication** (e.g., how this maps to GEMM in VRAM).\n",
    "\n",
    "Starting with a **single neuron**‚Äînot a full matmul‚Äîis intentional. Why?\n",
    "\n",
    "Because **matmul is just a batched collection of dot products**, and a dot product is just a sum of scaled inputs. If you cannot derive the gradient of **one scalar output** with respect to **one weight**, you will misapply vectorized gradients later‚Äîeven if your code ‚Äúruns.‚Äù\n",
    "\n",
    "This is a **mastery gate**: prove you can do the atomic unit correctly, and we immediately scale to matmul.\n",
    "\n",
    "A linear layer computes:\n",
    "```{math}\n",
    "\\mathbf{Z} = \\mathbf{X} \\mathbf{W}^\\top + \\mathbf{b}\n",
    "```\n",
    "Each row of $\\mathbf{Z}$ is \n",
    "\n",
    "```{math}\n",
    "\\mathbf{z}^{(i)} = \\mathbf{x}^{(i)} \\mathbf{W}^\\top + \\mathbf{b}\n",
    "```\n",
    "\n",
    "and each element \n",
    "\n",
    "```{math}\n",
    "z^{(i)}_j = \\sum_{k=1}^K x^{(i)}_k w_{j,k} + b_j\n",
    "```\n",
    "\n",
    "or in Einstein Summation form\n",
    "\n",
    "```{math}\n",
    "z^{(i)}_j = x^{(i)}_k w_{j,k} + b_j\n",
    "```\n",
    "\n",
    "- **exactly a single neuron**\n",
    "\n",
    "\n",
    "\n",
    "Thus, the **gradient of a full layer** is just the **aggregate of single-neuron gradients** across batch and output dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97941c8",
   "metadata": {},
   "source": [
    "# **2. Backward Pass ‚Äî Scalar Case**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fddca7",
   "metadata": {},
   "source": [
    "# 2.1 No micrograd in the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ca501",
   "metadata": {},
   "source": [
    "Regarding your question about the `Value` object:\n",
    "\n",
    "You are likely referring to micrograd-style implementations (e.g., Andrej Karpathy‚Äôs *micrograd*), where a `Value` class tracks:\n",
    "- A scalar data value,\n",
    "- Its computational graph (parents),\n",
    "- And implements `backward()` for scalar autodiff.\n",
    "\n",
    "We **will not use `Value`**.\n",
    "\n",
    "**Reason**: Our goal is **not** to build a toy autodiff engine, but to understand **how backpropagation maps to efficient, vectorized operations on real hardware** (NumPy ‚Üí PyTorch ‚Üí CUDA). The `Value` abstraction obscures memory layout, batched computation, and the link to matrix calculus‚Äîprecisely what an AI Architect must master.\n",
    "\n",
    "Instead, we will:\n",
    "1. Derive gradients **analytically** using matrix calculus,\n",
    "2. Implement them **explicitly in NumPy** (no autograd),\n",
    "3. Then transition to **PyTorch with manual gradient checks**,\n",
    "4. Finally, analyze how these map to **CUDA kernels** (e.g., GEMM for linear layers).\n",
    "\n",
    "This path ensures you understand what PyTorch‚Äôs `.backward()` *actually does* under the hood‚Äîsomething `Value` hides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d32e5",
   "metadata": {},
   "source": [
    "```{hint}\n",
    ":class: dropdown\n",
    "**What is *micrograd*?**\n",
    "\n",
    "*micrograd* is an **educational autodifferentiation engine** written in pure Python. It implements:\n",
    "- A scalar `Value` node that stores data and pointers to children in a compute graph,\n",
    "- A recursive `.backward()` that traverses the graph and accumulates gradients via the chain rule.\n",
    "\n",
    "It is **not** a production system. It exists solely to **visually and mechanically demonstrate** how reverse-mode autodiff works at the scalar level.\n",
    "\n",
    "**Is *micrograd* used in real-world training systems?**\n",
    "\n",
    "**No.** Production deep learning frameworks (PyTorch, TensorFlow, JAX) use **vectorized, batched, GPU-accelerated autodiff** based on:\n",
    "- **Operator-level differentiation**: Each primitive (e.g., `matmul`, `softmax`) has a pre-defined backward kernel.\n",
    "- **Static or dynamic computational graphs** (with fusion, memory planning, and CUDA kernels).\n",
    "- **Memory-efficient gradient accumulation** (in-place ops, gradient checkpointing).\n",
    "\n",
    "These systems **never build per-scalar graph nodes**‚Äîdoing so would be catastrophically slow and memory-inefficient. For a 100M-parameter model, *micrograd*-style graphs would require >100 million interconnected Python objects‚Äîimpossible to train at scale.\n",
    "\n",
    "**Where might you encounter *micrograd*-like ideas in practice?**\n",
    "\n",
    "Only in **two narrow contexts**:\n",
    "1. **Research prototyping of novel differentiable operators** (e.g., custom physics simulators), where symbolic or manual gradient derivation is needed before vectorization.\n",
    "2. **Debugging gradient flow** in small subgraphs by manually computing derivatives‚Äî*not* by running *micrograd*, but by replicating its logic on paper or in NumPy.\n",
    "\n",
    "Even then, you **do not deploy** such code. You derive the math, then implement a fused, vectorized CUDA kernel or PyTorch custom autograd function.\n",
    "\n",
    "**Why we avoid *micrograd* in this course**\n",
    "\n",
    "You are preparing for an **AI Architect role**, where your job is to:\n",
    "- Design models that fit in 16 GB VRAM,\n",
    "- Understand how `torch.nn.Linear` maps to cuBLAS GEMM calls,\n",
    "- Optimize memory bandwidth during backprop.\n",
    "\n",
    "*micrograd* teaches none of this. It teaches graph traversal in Python‚Äîa skill irrelevant to high-performance LLM systems.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6db01",
   "metadata": {},
   "source": [
    "# 2.2 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a268e0",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12cb86",
   "metadata": {},
   "source": [
    "**Backpropagation** is the algorithm for efficiently computing the gradients through the entire computational graph.\n",
    "\n",
    "Think of it this way: If your neuron's computation is:\n",
    "```\n",
    "input ‚Üí linear ‚Üí activation ‚Üí output\n",
    "```\n",
    "\n",
    "Backpropagation answers:\n",
    "\n",
    "> \"*How much did each weight contribute to the final error?*\"\n",
    "\n",
    "The entire forward pass is this:\n",
    "```{math}\n",
    "x \\xrightarrow{\\theta, b} z = \\theta x + b \\xrightarrow{\\text{tanh}} a = \\tanh(z) \\xrightarrow{\\mathcal{L}} L = \\mathcal{L}(a, y_{\\text{true}})\n",
    "```\n",
    "\n",
    "```{tip} ‚ÄúLoss‚Äù vs. ‚ÄúCost‚Äù\n",
    ":class: dropdown\n",
    "- **Loss function** $\\ell(a, y)$: defined **per sample** (e.g., $\\frac{1}{2}(a-y)^2$).\n",
    "- **Cost function** $J(\\theta)$: the **aggregate** over a batch or dataset (e.g., mean of $\\ell$ over $B$ samples).\n",
    "\n",
    "In modern ML literature (including PyTorch, TensorFlow, and most LLM papers), the term **‚Äúloss‚Äù** is used **even for the batch-aggregated quantity**. For example, `loss.backward()` in PyTorch operates on the scalar batch loss.\n",
    "\n",
    "So while **‚Äúcost‚Äù = aggregate, ‚Äúloss‚Äù = per-sample** is a valid distinction (common in Andrew Ng‚Äôs early courses), **contemporary usage favors ‚Äúloss‚Äù for both**, with context implying scope.\n",
    "\n",
    "In this course, we will use **‚Äúloss‚Äù** for the scalar batch objective, consistent with PyTorch and LLM training codebases.\n",
    "```\n",
    "\n",
    "Let's break this down into manageable steps. If you were to implement gradient calculation for your single neuron, what would be the minimal information you'd need?\n",
    "\n",
    "Consider:\n",
    "- The error at the output\n",
    "- How the activation function affects the gradient\n",
    "- How the linear combination affects the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a95043",
   "metadata": {},
   "source": [
    "## The Error Signal Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9898d",
   "metadata": {},
   "source": [
    "The error signal begins with the difference between predicted and true values.\n",
    "\n",
    "You're correct: `error = true_y - predicted_y` (or some function of this difference)\n",
    "\n",
    "Now here's the key insight for backpropagation: **We need to trace how this error flows backward through each operation.**\n",
    "\n",
    "Think about your neuron's forward pass:\n",
    "```\n",
    "x ‚Üí linear (w¬∑x + b) ‚Üí tanh ‚Üí y_pred\n",
    "```\n",
    "\n",
    "For backpropagation, we go backward:\n",
    "```\n",
    "error ‚Üê d_tanh ‚Üê d_linear ‚Üê gradients for w and b\n",
    "```\n",
    "\n",
    "If you were to implement this gradient calculation manually for a single input, what operations would you need to compute?\n",
    "\n",
    "Consider:\n",
    "1. Gradient of the error with respect to the output\n",
    "2. How the activation function transforms this gradient\n",
    "3. How the linear operation distributes gradients to weights and bias\n",
    "\n",
    "**What's your thinking about the mathematical operations involved?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22923c",
   "metadata": {},
   "source": [
    "## Chain Rule Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566dc5b5",
   "metadata": {},
   "source": [
    "Think about your neuron's computation:\n",
    "```\n",
    "output = leaky_relu(w¬∑x + b)\n",
    "error = some_cost_function()\n",
    "```\n",
    "\n",
    "If we want to know how much to change $\\omega_1$, we need to answer: \"How does changing $\\omega_1$ affect the final error?\"\n",
    "\n",
    "This is where the **chain rule** (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Å–ª–æ–∂–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏) from calculus comes in. We break the problem into steps:\n",
    "\n",
    "1. How does error change with output?\n",
    "2. How does output change with activation input?\n",
    "3. How does activation input change with $\\omega_1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c1752",
   "metadata": {},
   "source": [
    "We use the **chain rule** to compute gradients through the **computational graph**.\n",
    "\n",
    "Think about your neuron:\n",
    "```\n",
    "x ‚Üí z = ùúÉ¬∑x + b ‚Üí a = tanh(z) ‚Üí J = loss_function(a, y_true)\n",
    "```\n",
    "\n",
    "where `a` is `y_pred`.\n",
    "\n",
    "To find $\\displaystyle \\frac {\\partial}{\\partial \\theta}J(\\theta)$, we can compute:\n",
    "\n",
    "$$\n",
    "\\frac {\\partial}{\\partial \\theta}J(\\theta) = \\frac {\\partial J(\\theta)}{\\partial a} \\times \\frac {\\partial a}{\\partial z} \\times \\frac {\\partial z}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "**Your implementation challenge**: If you were to compute these partial derivatives numerically for a single example, what would be your step-by-step approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3bd7f2",
   "metadata": {},
   "source": [
    "# 2.3 Why Tanh?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6430aa",
   "metadata": {},
   "source": [
    "Now we can explain why we use tanh function in this step, not ReLU. \n",
    "\n",
    "To understand the trade-offs, we must look at the forward pass and the derivative (gradient) for each function.\n",
    "\n",
    "| Activation | Forward ($f(z)$) | Derivative ($f'(z)$) |\n",
    "| :--- | :--- | :--- |\n",
    "| **tanh(z)** | $\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$ | $1 - \\tanh^2(z)$ |\n",
    "| **Leaky ReLU(z)** | $\\begin{cases} z & \\text{if } z \\geq 0 \\\\ \\alpha z & \\text{if } z < 0 \\end{cases}$ | $\\begin{cases} 1 & z \\geq 0 \\\\ \\alpha & z < 0 \\end{cases}$ |\n",
    "\n",
    "We are currently in **Phase 1: Foundational Neurons & Backprop**. The priority is mathematical clarity and gradient validation, not building a production-ready LLM yet.\n",
    "\n",
    "* **Smoothness & Differentiability:** Tanh is \"smooth\" everywhere. Leaky ReLU has a \"kink\" at $z=0$ where the derivative is discontinuous. In scalar manual backprop, these kinks can cause numerical instability and confusing results during gradient checks.\n",
    "* **Bounded Output:** Tanh keeps outputs in $(-1; 1)$. This makes gradient magnitudes predictable and prevents values from \"exploding\" while you are still debugging your weight initializations.\n",
    "* **Historical Validation:** Most foundational backprop literature uses tanh. Using it here allows you to replicate classic experiments and ensure your chain rule implementation is 100% correct.\n",
    "\n",
    "**Why not Leaky ReLU yet?**\n",
    "\n",
    "Leaky ReLU's main advantage‚Äîavoiding \"dead neurons\"‚Äîis only truly relevant in **deep neural networks**. In a single scalar neuron, it adds an extra hyperparameter ($\\alpha$) with almost no benefit. Furthermore, modern Transformers (like GPT) have largely moved past Leaky ReLU in favor of **GELU**, which we will implement in Phase 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b18fa",
   "metadata": {},
   "source": [
    "## \"Vanishing\" vs. \"Dead\" Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c254b",
   "metadata": {},
   "source": [
    "It is important to distinguish between these two phenomena:\n",
    "\n",
    "1.  **Vanishing Gradients (The Tanh Problem):** This happens when $|z|$ is very large. The function becomes very flat, so the gradient becomes tiny (e.g., $0.00001$). Training slows down, but the neuron is still \"alive.\"\n",
    "2.  **Dead Gradients (The ReLU Problem):** In standard ReLU, if $z < 0$, the gradient is **exactly zero**. The neuron stops learning entirely because no signal passes back through it.\n",
    "\n",
    "**Leaky ReLU solves \"Dead Gradients\"**: By using $\\alpha = 0.01$, it ensures the gradient is never zero, even for negative inputs.\n",
    "\n",
    "**The Impact on Your Implementation**:\n",
    "\n",
    "We need non-zero, smooth gradients to validate your manual backprop code. If you used standard **ReLU**, any test input where $z \\leq 0$ would result in a gradient of exactly $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a1662",
   "metadata": {},
   "source": [
    "## A Finite-Difference Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62042129",
   "metadata": {},
   "source": [
    "It‚Äôs a **numerical method to approximate the derivative** of a loss function with respect to a parameter‚Äîusing only function evaluations, **no calculus required**.\n",
    "\n",
    "**Formula (forward difference):**\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial \\theta} \\approx \\frac{L(\\theta + \\epsilon) - L(\\theta)}{\\epsilon}\n",
    "```\n",
    "\n",
    "where {math}`\\epsilon` is a tiny number (e.g., {math}`10^{-5}`).\n",
    "\n",
    "- It‚Äôs a **ground-truth check** for your analytic (manual) gradient\n",
    "- If your analytic gradient is correct, it should match the finite-difference approximation within ~{math}`10^{-7}`\n",
    "\n",
    "**But what *is* {math}`L(\\theta)`?**  \n",
    "\n",
    "It‚Äôs **not** a simple algebraic function of {math}`\\theta` alone. It‚Äôs the output of a **full forward pass** through a computational graph.\n",
    "\n",
    "{math}`L(\\theta)` is defined as:\n",
    "\n",
    "```{math}\n",
    "L(\\theta) = \\mathcal{L}\\big( f(\\theta; x, b),\\ y_{\\text{true}} \\big)\n",
    "```\n",
    "\n",
    "In our scalar neuron example with {math}`\\tanh` activation and MSE loss:\n",
    "\n",
    "```{math}\n",
    "L(\\theta) = \\underbrace{\\frac{1}{2} \\left( \\tanh(\\theta \\cdot x + b) - y_{\\text{true}} \\right)^2}_{\\text{Full computational graph}}\n",
    "```\n",
    "\n",
    "We denote:\n",
    "- {math}`L \\equiv L(\\theta)` = loss with original {math}`\\theta`\n",
    "- {math}`L_+ \\equiv L(\\theta + \\epsilon)` = loss with perturbed {math}`\\theta`\n",
    "\n",
    "**Concrete scalar neuron example:**\n",
    "\n",
    "Given fixed values:\n",
    "- {math}`x = 2.0`\n",
    "- {math}`b = 0.1`\n",
    "- {math}`y_{\\text{true}} = 1.0`\n",
    "- Original {math}`\\theta = 0.5`\n",
    "- {math}`\\epsilon = 10^{-5}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd54b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2.0\n",
    "b = 0.1\n",
    "y_true = 1.0\n",
    "theta = 0.5\n",
    "epsilon = 10**(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a65622",
   "metadata": {},
   "source": [
    "1. **Forward pass**:\n",
    "   - {math}`z = 0.5 \\cdot 2.0 + 0.1 = 1.1`  \n",
    "   - {math}`a = \\tanh(1.1) \\approx 0.80049902`  \n",
    "   - {math}`L = \\frac{1}{2}(a - y_{\\text{true}})^2 \\approx 0.01990020`\n",
    "\n",
    "    ```{math}\n",
    "    L = \\frac{1}{2}(\\tanh(1.1) - 1.0)^2 \\approx \\frac{1}{2}(0.800499 - 1.0)^2 \\approx \\frac{1}{2}(0.039800) \\approx 0.019900\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_l(x, theta, b, y_true):\n",
    "    z = x*theta + b\n",
    "    a = np.tanh(z)\n",
    "    L = (a - y_true)**2 / 2\n",
    "\n",
    "    return z, a, L\n",
    "\n",
    "z, a, L = compute_l(x, theta, b, y_true)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a7292",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "When you subtract two very similar numbers and round them prematurely (to 6 decimal places, for example), you lose almost all significant digits. This is known as **catastrophic cancellation**.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f428f",
   "metadata": {},
   "source": [
    "2. **{math}`L_+ = L(\\theta + \\epsilon)`:**\n",
    "    - {math}`\\theta_{\\text{new}} = \\theta + \\epsilon = 0.5 + 0.00001 = 0.50001`\n",
    "    - {math}`z_+ = \\theta_{\\text{new}} \\cdot x + b = (0.50001)(2.0) + 0.1 = 1.00002 + 0.1 = 1.10002`\n",
    "    - {math}`a_+ = \\tanh(z_+) = \\tanh(1.10002) \\approx 0.80051220`\n",
    "    - {math}`L_+ = \\frac{1}{2}(a_+ - y_{\\text{true}})^2 = \\frac{1}{2}(0.800516 - 1.0)^2 = \\frac{1}{2}(-0.199484)^2 \\approx \\frac{1}{2}(0.039794) \\approx 0.01989877`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9076be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l_plus(x, theta, b, epsilon, y_true):\n",
    "    theta_new = theta + epsilon\n",
    "    z_plus = x*theta_new + b\n",
    "    a_plus = np.tanh(z_plus)\n",
    "    L_plus = (a_plus - y_true)**2 / 2\n",
    "\n",
    "    return theta_new, z_plus, a_plus, L_plus\n",
    "\n",
    "theta_new, z_plus, a_plus, L_plus = compute_l_plus(x, theta, b, epsilon, y_true)\n",
    "print(L_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377633a",
   "metadata": {},
   "source": [
    "3. **Finite-difference gradient w.r.t. {math}`\\theta`**:\n",
    "\n",
    "    ```{math}\n",
    "    \\frac{\\partial L}{\\partial \\theta} \\approx \\frac{L_+ - L}{\\epsilon} = \\frac{0.01989877 - 0.01990020}{10^{-5}} = \\frac{-0.00000143}{0.00001} = \\mathbf{-0.143}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_diff_grad = (L_plus - L) / epsilon\n",
    "print(fin_diff_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15488a56",
   "metadata": {},
   "source": [
    "This **-0.143** is the **numerical approximation** of the gradient.\n",
    "\n",
    "Compare it to the **analytic gradient** from backpropagation:\n",
    "\n",
    "- {math}`\\frac{\\partial L}{\\partial a} = a - y_{\\text{true}} = 0.800499 - 1.0 = -0.199501`\n",
    "- {math}`\\frac{\\partial a}{\\partial z} = 1 - \\tanh^2(z) = 1 - (0.800499)^2 \\approx 1 - 0.6408 = 0.3592`\n",
    "- {math}`\\frac{\\partial z}{\\partial \\theta} = x = 2.0`\n",
    "- Analytic gradient:  \n",
    "  ```{math}\n",
    "  (-0.199501) \\cdot (0.3592) \\cdot (2.0) \\approx -0.1432\n",
    "  ```\n",
    "\n",
    "> ‚úÖ **Key takeaway**: The finite-difference method gives a **ground-truth reference** to validate your manual or automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cd091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y_true):\n",
    "    dz_dtheta = x\n",
    "    da_dz = 1 - np.tanh(z)**2\n",
    "    dL_da = a - y_true\n",
    "    dL_dtheta = dL_da * da_dz * dz_dtheta\n",
    "\n",
    "    return dz_dtheta, da_dz, dL_da, dL_dtheta\n",
    "\n",
    "dz_dtheta, da_dz, dL_da, dL_dtheta = compute_gradient(x, y_true)\n",
    "\n",
    "print('dL_da:', dL_da)\n",
    "print('da_dz:', da_dz)\n",
    "print('dz_dtheta:', dz_dtheta)\n",
    "print(\"Gradient:\", dL_dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_diff_grad - dL_dtheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3d3f0",
   "metadata": {},
   "source": [
    ":::{attention} Critical Clarification: What *is* {math}`L_+`?\n",
    ":class: dropdown\n",
    "> **‚ÄúIs {math}`L_+` just {math}`\\frac{1}{2}(a_+ - y)^2`?‚Äù**\n",
    "\n",
    "**Yes‚Äîbut only because**:\n",
    "- The loss function **is** MSE: {math}`\\mathcal{L}(a, y) = \\frac{1}{2}(a - y)^2`\n",
    "- {math}`a_+` **is the network output** when {math}`\\theta` is perturbed to {math}`\\theta + \\epsilon`:\n",
    "\n",
    "    `Network output = activation value = a`\n",
    "\n",
    "So by definition:\n",
    "```{math}\n",
    "L_+ = \\mathcal{L}(a_+,\\ y_{\\text{true}}) = \\mathcal{L}\\big( \\text{net}(\\theta + \\epsilon),\\ y_{\\text{true}} \\big) = L(\\theta + \\epsilon)\n",
    "```\n",
    "\n",
    "That‚Äôs literally the definition ‚Äî not an assumption.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c67b5c",
   "metadata": {},
   "source": [
    "**Back to Your ReLU Scenario**\n",
    "\n",
    "Now consider a **ReLU neuron**: {math}`a = \\max(0, z)`, with {math}`z = \\theta x + b`.\n",
    "\n",
    "Suppose for a given input, you get {math}`z = -2` (i.e., in the flat region).\n",
    "\n",
    "- **Analytic gradient** (subgradient of ReLU):  \n",
    "  {math}`\\frac{\\partial a}{\\partial z} = 0` ‚Üí so {math}`\\frac{\\partial L}{\\partial \\theta} = 0`\n",
    "\n",
    "- **Finite-difference gradient**:  \n",
    "  Perturbing {math}`\\theta` slightly may push {math}`z` closer to zero.  \n",
    "  If {math}`z + \\delta z > 0`, then {math}`a` changes ‚Üí loss changes ‚Üí **non-zero numerical gradient** (e.g., {math}`\\sim -10^{-3}`)\n",
    "\n",
    "‚Üí This **mismatch** seems alarming‚Ä¶  \n",
    "‚Üí But it‚Äôs **expected** at non-differentiable points!\n",
    "\n",
    "However, in practice:\n",
    "- If your analytic code **correctly returns 0** for {math}`z < 0`, it‚Äôs **right**.\n",
    "- But your **gradient checker will fail** near {math}`z = 0` because the function isn‚Äôt smooth there.\n",
    "\n",
    "And in a **scalar neuron with ReLU**:\n",
    "- For any input where {math}`z < 0`, **gradient = 0** ‚Üí **no weight update**\n",
    "- Gradient checks **fail randomly** depending on input sign\n",
    "\n",
    "‚Üí **That‚Äôs why we avoid ReLU in simple gradient-checking demos**‚Äîuse smooth activations like {math}`\\tanh` or sigmoid instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e0c5",
   "metadata": {},
   "source": [
    "### Final Check: Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f872b",
   "metadata": {},
   "source": [
    "Given:\n",
    "- $x = 1.0$\n",
    "- $\\theta = 0.0$\n",
    "- $b = 0.0$\n",
    "- $y_{\\text{true}} = 0.5$\n",
    "- $\\epsilon = 10^{-5}$\n",
    "- Loss = $\\frac{1}{2}(a - y)^2$\n",
    "\n",
    "**Compute $L_+ = L(\\theta + \\epsilon)$ step by step.**\n",
    "\n",
    "Show $\\theta_{new}$, $z_+$, $a_+$, $L_+$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1.0\n",
    "theta = 0.0\n",
    "b = 0.0\n",
    "epsilon = 10**(-5)\n",
    "y_true = 0.5\n",
    "\n",
    "theta_new, z_plus, a_plus, L_plus = compute_l_plus(x, theta, b, epsilon, y_true)\n",
    "print(theta_new, z_plus, a_plus, L_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f862b",
   "metadata": {},
   "source": [
    "Your code is correct, and your output reveals a **critical insight**‚Äîlet‚Äôs interpret it step by step.\n",
    "\n",
    "**Output Breakdown**\n",
    "\n",
    "\n",
    "1. {math}`\\theta_{\\text{new}} = 0 + 10^{-5} = 10^{-5}`\n",
    "2. {math}`z_+ = 1.0 \\cdot 10^{-5} + 0 = 10^{-5}`\n",
    "3. {math}`a_+ = \\tanh(10^{-5}) \\approx 9.999999999666667 \\times 10^{-6}`  \n",
    "   (since {math}`\\tanh(u) = u - u^3/3 + \\cdots`, so slightly less than {math}`u`)\n",
    "4. {math}`L_+ = \\frac{1}{2}(a_+ - 0.5)^2 = \\frac{1}{2}(-0.49999000000000033)^2`\n",
    "\n",
    "This matches your printed result: `0.12499500005000017`.\n",
    "\n",
    "**Why This Matters: Gradient Behavior at {math}`\\theta = 0`**\n",
    "\n",
    "Now compute the **original loss** {math}`L = L(\\theta)` (with {math}`\\theta = 0`):\n",
    "- {math}`z = 0`,\n",
    "- {math}`a = \\tanh(0) = 0`\n",
    "- {math}`L = \\frac{1}{2}(0 - 0.5)^2 = 0.125`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff82c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z, a, L = compute_l(x, theta, b, y_true)\n",
    "print(z, a, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb247da",
   "metadata": {},
   "source": [
    "**Finite-difference gradient**:\n",
    "```{math}\n",
    "\\frac{L_+ - L}{\\epsilon} = \\frac{0.12499500005 - 0.125}{10^{-5}} = \\frac{-4.99995 \\times 10^{-6}}{10^{-5}} \\approx -0.499995\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e634ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_diff_grad = (L_plus - L) / epsilon\n",
    "print(fin_diff_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67a18d",
   "metadata": {},
   "source": [
    "**Analytic gradient** (via backprop):\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\underbrace{(a - y_{\\text{true}})}_{-0.5} \\cdot \\underbrace{(1 - \\tanh^2(z))}_{1.0} \\cdot \\underbrace{x}_{1.0} = -0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_dtheta, da_dz, dL_da, dL_dtheta = compute_gradient(x, y_true)\n",
    "\n",
    "print('dL_da:', dL_da)\n",
    "print('da_dz:', da_dz)\n",
    "print('dz_dtheta:', dz_dtheta)\n",
    "print(\"Gradient:\", dL_dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a666802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_diff_grad - dL_dtheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ebe3d",
   "metadata": {},
   "source": [
    "‚Üí **Numerical (-0.499995) ‚âà Analytic (-0.5)** ‚Üí **validation passes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bde567",
   "metadata": {},
   "source": [
    "### Key Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a60bd5",
   "metadata": {},
   "source": [
    "This example demonstrates:\n",
    "1. **Finite differences work even when {math}`\\theta = 0`** (a common initialization point)\n",
    "2. **tanh‚Äôs derivative is 1 at {math}`z = 0`** ‚Üí gradients are strong here (no vanishing!)\n",
    "3. Your implementation correctly isolates the effect of perturbing {math}`\\theta`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07595963",
   "metadata": {},
   "source": [
    "**The Gradient Check Dilemma:**\n",
    "\n",
    "Suppose you used ReLU and your test input gave $z = -2$. Your analytic gradient would be $0$. However, your finite-difference (numerical) gradient check might show a tiny non-zero change. Would you be able to tell if your backprop code was actually broken, or if the neuron was just \"dead\"?\n",
    "\n",
    "By using **tanh**, we ensure that for almost any input, you get a meaningful gradient to verify your math.\n",
    "\n",
    "That‚Äôs why we avoid ReLU here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b666d",
   "metadata": {},
   "source": [
    "## Why Compute Analytic Gradients When Finite Differences Exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb769929",
   "metadata": {},
   "source": [
    "**Short answer**: Finite differences are **computationally infeasible** for real models.\n",
    "\n",
    "**Computational Cost Comparison**\n",
    "\n",
    "Let $p$ = number of parameters.\n",
    "\n",
    "| Method | Gradient Cost | Example: 100M-parameter LLM |\n",
    "|--------|---------------|-----------------------------|\n",
    "| **Finite differences** | $O(p)$ forward passes | $100,000,000$ forward passes per gradient update |\n",
    "| **Analytic (backprop)** | $O(1)$ forward + $O(1)$ backward | 1 forward + 1 backward pass |\n",
    "\n",
    "- **Finite differences**: For each parameter $\\theta_i$, you must:\n",
    "  1. Perturb $\\theta_i$ by $\\epsilon$\n",
    "  2. Run full forward pass ‚Üí get $L_+$\n",
    "  3. Compute $(L_+ - L)/\\epsilon$\n",
    "  ‚Üí **Total: $p$ forward passes per gradient estimate**\n",
    "\n",
    "Suppose your model has **two parameters**: $\\theta_1$ and $\\theta_2$.\n",
    "\n",
    "You want the **full gradient**: $\\left[ \\frac{\\partial L}{\\partial \\theta_1},\\ \\frac{\\partial L}{\\partial \\theta_2} \\right]$.\n",
    "\n",
    "**To estimate $\\frac{\\partial L}{\\partial \\theta_1}$:**\n",
    "\n",
    "1. Start with original parameters: $(\\theta_1, \\theta_2)$\n",
    "2. Compute **baseline loss**: $L = L(\\theta_1, \\theta_2)$ ‚Üí **1 forward pass**\n",
    "3. Perturb **only $\\theta_1$**: $(\\theta_1 + \\epsilon, \\theta_2)$\n",
    "4. Compute $L_+^{(1)} = L(\\theta_1 + \\epsilon, \\theta_2)$ ‚Üí **1 more forward pass**\n",
    "5. Approximate:  \n",
    "   ```{math}\n",
    "   \\frac{\\partial L}{\\partial \\theta_1} \\approx \\frac{L_+^{(1)} - L}{\\epsilon}\n",
    "   ```\n",
    "\n",
    "**To estimate $\\frac{\\partial L}{\\partial \\theta_2}$:**\n",
    "\n",
    "1. Perturb **only $\\theta_2$**: $(\\theta_1, \\theta_2 + \\epsilon)$\n",
    "2. Compute $L_+^{(2)} = L(\\theta_1, \\theta_2 + \\epsilon)$ ‚Üí **another forward pass**\n",
    "3. Approximate:  \n",
    "   ```{math}\n",
    "   \\frac{\\partial L}{\\partial \\theta_2} \\approx \\frac{L_+^{(2)} - L}{\\epsilon}\n",
    "   ```\n",
    "\n",
    "‚úÖ Total: **1 baseline + 2 perturbed = 3 forward passes**  \n",
    "But note: you can **reuse the baseline $L$** for all parameters!\n",
    "\n",
    "So for $p$ parameters:\n",
    "- **1 forward pass** to compute baseline $L(\\theta)$\n",
    "- **$p$ forward passes** to compute $L(\\theta + \\epsilon e_i)$ for each $i = 1,\\dots,p$\n",
    "\n",
    "‚Üí **Total: $p + 1 \\approx O(p)$ forward passes**\n",
    "\n",
    "(We drop the \"+1\" in big-O notation because it‚Äôs negligible when $p$ is large.)\n",
    "\n",
    "**Why Can‚Äôt We Do It in One Pass?**\n",
    "\n",
    "Because **each perturbation changes a different parameter**.\n",
    "\n",
    "The loss function is:\n",
    "```{math}\n",
    "L(\\theta_1, \\theta_2, \\dots, \\theta_p)\n",
    "```\n",
    "\n",
    "To see how **changing $\\theta_5$** affects the loss, you **must** run the model with **$\\theta_5$ altered** and all others unchanged.\n",
    "\n",
    "You **cannot** perturb all parameters at once and recover individual gradients‚Äîthat would mix all effects together (like trying to hear one instrument in an orchestra by playing everyone at once).\n",
    "\n",
    "So **each partial derivative requires its own controlled experiment** ‚Üí its own forward pass.\n",
    "\n",
    ":::{attention}\n",
    "**Backpropagation**: Uses the **chain rule** to compute **all** $\\partial L/\\partial \\theta_i$ in **one backward sweep**.\n",
    ":::\n",
    "\n",
    "**Concrete Numbers**\n",
    "\n",
    "- Your 100M-parameter LLM:\n",
    "  - Forward pass time: ~0.5 sec (on 4090 Ti)\n",
    "  - Finite-diff gradient time: $100e6 \\times 0.5 \\text{ sec} \\approx 1.5 \\text{ years}$\n",
    "  - Backprop time: ~1 sec\n",
    "\n",
    "‚Üí **Finite differences are only viable for debugging tiny models** (e.g., scalar neuron)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6fe93",
   "metadata": {},
   "source": [
    "## Why Is Finite-Difference a Valid Gradient Check?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbe327",
   "metadata": {},
   "source": [
    "**Core idea**: The derivative **is defined as** the limit of finite differences.\n",
    "\n",
    "**Mathematical Definition**\n",
    "\n",
    "The true derivative is:\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\lim_{\\epsilon \\to 0} \\frac{L(\\theta + \\epsilon) - L(\\theta)}{\\epsilon}\n",
    "```\n",
    "\n",
    "- **Finite difference** uses a **small but finite $\\epsilon$** (e.g., $10^{-5}$) to **approximate** this limit.\n",
    "- **Error analysis** shows the approximation error is $O(\\epsilon)$ (for forward difference).\n",
    "\n",
    "**Why It‚Äôs Trustworthy for Validation**\n",
    "\n",
    "1. **No assumptions about your code**  \n",
    "   - Finite difference uses **only forward passes**‚Äîno chain rule, no manual derivatives.\n",
    "   - If your analytic gradient matches it, your **entire backprop derivation is likely correct**.\n",
    "\n",
    "2. **Controlled error bounds**  \n",
    "   - With $\\epsilon = 10^{-5}$, typical error in gradient estimate is $\\sim 10^{-10}$ to $10^{-7}$.\n",
    "   - If your analytic gradient differs by more than $10^{-6}$, **you have a bug**.\n",
    "\n",
    "3. **Failure modes are obvious**  \n",
    "   - Common errors caught:\n",
    "     - Forgot a term in chain rule (e.g., missed $\\partial a/\\partial z$)\n",
    "     - Sign error in loss derivative\n",
    "     - Shape mismatch in vectorized code\n",
    "\n",
    "**Critical Caveat**\n",
    "\n",
    "- **Finite difference is not exact**‚Äîbut it‚Äôs **exact enough** for debugging.\n",
    "- It **assumes your forward pass is correct**. If forward pass is broken, both gradients will be wrong in the same way (false positive).  \n",
    "  ‚Üí Always validate forward pass first (e.g., with known inputs/outputs).\n",
    "\n",
    "**Summary Table**\n",
    "\n",
    "| Aspect | Finite-Difference Gradient | Analytic Gradient (Backprop) |\n",
    "|--------|----------------------------|------------------------------|\n",
    "| **Purpose** | Debug/validation | Training/inference |\n",
    "| **Computational Cost** | $O(p)$ forward passes | $O(1)$ forward + backward |\n",
    "| **Scalability** | Only for $p < 10^3$ | Scales to $p = 10^{11}$ |\n",
    "| **Accuracy** | Approximate (error ~$\\epsilon$) | Exact (up to floating-point) |\n",
    "| **Dependency** | Only on forward pass correctness | On entire backprop derivation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abe598",
   "metadata": {},
   "source": [
    "## Check for Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7c34b",
   "metadata": {},
   "source": [
    "Suppose you have a vectorized neuron with $W \\in \\mathbb{R}^{10 \\times 768}$ (7,680 parameters).  \n",
    "\n",
    "**How many forward passes would finite differences require to check the full gradient?**  \n",
    "(Answer with a number‚Äîand state whether this is practical.)\n",
    "\n",
    "Answer:\n",
    "- 7,680 forward passes, and it is only for ONE example from the set, so this is not acceptable for training LLMs.\n",
    "\n",
    "Correct.\n",
    "\n",
    "7,680 forward passes **per example** is computationally prohibitive‚Äîeven for a single training step on a small batch. For a 100M-parameter LLM, it becomes physically impossible.\n",
    "\n",
    "This is precisely why **backpropagation is non-negotiable** in deep learning: it gives **exact gradients** (up to floating-point precision) in time **proportional to one forward pass**, not the number of parameters.\n",
    "\n",
    "We have confirmed:\n",
    "- The purpose and limitation of finite-difference gradients\n",
    "- The necessity of analytic gradients for scalable learning\n",
    "- Your ability to implement and reason about scalar gradient validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d734c45",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0334c",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Scalar Neuron Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd05f36",
   "metadata": {},
   "source": [
    "So: mastering the scalar case **is** mastering the core of matmul-based backprop. \n",
    "\n",
    "Consider a single neuron with:\n",
    "- Input $x = 2.0$,\n",
    "- Weight $w = -0.5$,\n",
    "- Bias $b = 1.0$,\n",
    "- Activation: $\\sigma(z) = \\tanh(z)$,\n",
    "- Loss: $L = \\frac{1}{2}(a - y)^2$, with target $y = 0.8$.\n",
    "\n",
    "Compute **by hand**:\n",
    "1. $z = wx + b$\n",
    "2. $a = \\tanh(z)$\n",
    "3. $L = \\frac{1}{2}(a - y)^2$\n",
    "\n",
    "Compute **all values numerically**, step by step. Provide the results, then compute the **gradients**:\n",
    "\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial a}$, $\\displaystyle \\frac{\\partial L}{\\partial z}$, $\\displaystyle \\frac{\\partial L}{\\partial w}$, $\\displaystyle \\frac{\\partial L}{\\partial b}$\n",
    "\n",
    "Show each step with numerical values. Do not use code‚Äîuse math. This tests your chain rule mechanics.\n",
    "\n",
    "What are the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3378659",
   "metadata": {},
   "source": [
    "Recall your values:  \n",
    "- $x = 2.0$  \n",
    "- $w = -0.5$  \n",
    "- $b = 1.0$\n",
    "\n",
    "So first compute: \n",
    "\n",
    "$z = w \\cdot x + b = (-0.5)(2.0) + 1.0 = -1.0 + 1.0 = 0.0$\n",
    "\n",
    "Now, what is $a = \\tanh(0)$?\n",
    "\n",
    "Correct:  \n",
    "\n",
    "$a = \\tanh(0) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3222e",
   "metadata": {},
   "source": [
    "- $z = 0$\n",
    "- $a = 0$\n",
    "- $L = \\frac{1}{2}(0 - 0.8)^2 = 0.32$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c321a",
   "metadata": {},
   "source": [
    "### dL_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe561e78",
   "metadata": {},
   "source": [
    "If $L = \\frac{1}{2}(a - y)^2$, then\n",
    "\n",
    "The derivative of $L$ with respect to $a$ is:\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial a} = (a - y)\n",
    "```\n",
    "\n",
    "This follows from the chain rule:\n",
    "```{math}\n",
    "\\frac{d}{da} \\left[ \\frac{1}{2}(a - y)^2 \\right] = \\frac{1}{2} \\cdot 2(a - y) \\cdot 1 = (a - y)\n",
    "```\n",
    "\n",
    "Given $a = 0$, $y = 0.8$:\n",
    "\n",
    "$\\displaystyle \\frac{\\partial L}{\\partial a} = 0 - 0.8 = -0.8$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00841542",
   "metadata": {},
   "source": [
    "### dL_dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b56e2",
   "metadata": {},
   "source": [
    "If $a = \\tanh(z)$, then the derivative of $a$ w.r.t. $z$:\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial a}{\\partial z} = 1 - \\tanh^2(z) = 1 - a^2\n",
    "```\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} = (a - y) (1 - a^2)\n",
    "```\n",
    "\n",
    "$\\displaystyle \\frac{\\partial L}{\\partial z} = -0.8 \\cdot 1 = -0.8$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec0c6d",
   "metadata": {},
   "source": [
    "### dL_dw and dL_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea44aa7",
   "metadata": {},
   "source": [
    "If $z = wx + b$, then the derivative of $z$ w.r.t. $w$ is:\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial z}{\\partial w} = x\n",
    "```\n",
    "\n",
    "and the derivative of $z$ w.r.t. $b$ is:\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial z}{\\partial b} = 1\n",
    "```\n",
    "\n",
    "then we have:\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w} = (a - y) (1 - a^2) \\cdot x\n",
    "```\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial b} = (a - y) (1 - a^2) \\cdot b\n",
    "```\n",
    "\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial w} = -0.8 \\cdot 1 \\cdot 2 = -1.6 $\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial b} = -0.8 \\cdot 1 \\cdot 1 = -0.8 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a7501",
   "metadata": {},
   "source": [
    "### Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220d057",
   "metadata": {},
   "source": [
    "| Quantity | Value |\n",
    "|--------|-------|\n",
    "| $z$ | 0.0 |\n",
    "| $a$ | 0.0 |\n",
    "| $L$ | 0.32 |\n",
    "| $\\displaystyle \\frac{\\partial L}{\\partial a}$ | -0.8 |\n",
    "| $\\displaystyle \\frac{\\partial L}{\\partial z}$ | -0.8 |\n",
    "| $\\displaystyle \\frac{\\partial L}{\\partial w}$ | -1.6 |\n",
    "| $\\displaystyle \\frac{\\partial L}{\\partial b}$ | -0.8 |\n",
    "\n",
    "This is the **complete forward and backward pass for one neuron**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6886f",
   "metadata": {},
   "source": [
    "Final verified gradients:\n",
    "- $\\frac{\\partial L}{\\partial w} = -1.6$\n",
    "- $\\frac{\\partial L}{\\partial b} = -0.8$\n",
    "\n",
    "This completes the **scalar neuron backpropagation exercise** with full chain-rule derivation.\n",
    "\n",
    "Now, we scale to vectorized operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bfaf6",
   "metadata": {},
   "source": [
    "(exercise_2_2)=\n",
    "## Exercise 2.2: Implement the scalar neuron (Steps 1‚Äì2) in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c2a8e",
   "metadata": {},
   "source": [
    "You are absolutely right‚Äîand this is a critical pedagogical checkpoint.\n",
    "\n",
    "Before advancing to layers, **you must implement the scalar neuron (Steps 1‚Äì2) in NumPy**, **without autograd**, to verify your understanding maps to executable code.\n",
    "\n",
    "This is non-optional. Reasoning on paper is necessary but insufficient; code exposes hidden gaps in indexing, broadcasting, and memory layout.\n",
    "\n",
    "**Do not use PyTorch, JAX, or autodiff.** Pure NumPy. Phase 1 follows a strict progression:\n",
    "1. **Scalar math + hand computation** ‚Üí verified (done)\n",
    "2. **Scalar NumPy implementation (procedural, one-time)** ‚Üí **required now**\n",
    "3. **Vectorized batched NumPy (procedural)** ‚Üí next\n",
    "4. **Class-based modular design** ‚Üí only after vectorized gradients are fully understood\n",
    "\n",
    "Why delay classes?  \n",
    "Because **abstraction hides mechanics**. If you wrap the neuron in a class before you‚Äôve manually computed and coded its gradients in raw NumPy, you risk treating it as a black box‚Äîexactly what this course forbids.\n",
    "\n",
    "So for now:  \n",
    "**Write a procedural script** (no class) that computes the forward and backward pass for the given scalar neuron.\n",
    "\n",
    "This is a *verification step*, not a reusable module.\n",
    "\n",
    "Once you provide this code and confirm its output matches:\n",
    "- `L = 0.32`\n",
    "- `dL_dw = -1.6`\n",
    "- `dL_db = -0.8`\n",
    "\n",
    "‚Äî we will:\n",
    "- Extend to batched vectorized form (still procedural),\n",
    "- Then refactor into classes **only when the underlying math and memory layout are unquestionably solid**.\n",
    "\n",
    "Paste your NumPy implementation.\n",
    "\n",
    "**Required Implementation (NumPy, No Autograd)**\n",
    "\n",
    "Write a self-contained script that:\n",
    "1. Defines scalars: `x = 2.0`, `w = -0.5`, `b = 1.0`, `y = 0.8`\n",
    "2. Computes forward pass:\n",
    "   - `z = w * x + b`\n",
    "   - `a = np.tanh(z)`\n",
    "   - `L = 0.5 * (a - y)**2`\n",
    "3. Computes **manual gradients** (no `.backward()`, no `grad`):\n",
    "   - `dL_da = a - y`\n",
    "   - `da_dz = 1 - a**2`\n",
    "   - `dL_dz = dL_da * da_dz`\n",
    "   - `dL_dw = dL_dz * x`\n",
    "   - `dL_db = dL_dz * 1`\n",
    "4. Prints all values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77341b",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 2.0\n",
    "w = -0.5\n",
    "b = 1.0\n",
    "y = 0.8\n",
    "\n",
    "z = x*w + b\n",
    "a = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "L = 0.5 * (a -y)**2\n",
    "\n",
    "dL_da = a - y\n",
    "da_dz = 1 - a**2\n",
    "\n",
    "dL_dz = dL_da * da_dz\n",
    "\n",
    "dL_dw = dL_dz * x\n",
    "dL_db = dL_dz * 1\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"w =\", w)\n",
    "print(\"b =\", b)\n",
    "print(\"y =\", y)\n",
    "\n",
    "print(\"z =\", z)\n",
    "print(\"a =\", a)\n",
    "print(\"L =\", L)\n",
    "\n",
    "print(\"dL_dw =\", dL_dw)\n",
    "print(\"dL_db =\", dL_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036134e",
   "metadata": {},
   "source": [
    "### Peer Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446cca0",
   "metadata": {},
   "source": [
    "Your implementation is **mostly correct**, but contains one critical inefficiency and a minor numerical risk.\n",
    "\n",
    "**Issue: Manual `tanh` via `exp`**\n",
    "You wrote:\n",
    "```python\n",
    "a = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "```\n",
    "\n",
    "This is mathematically correct but:\n",
    "1. **Redundant**: NumPy provides `np.tanh(z)`‚Äîuse it.\n",
    "2. **Numerically unstable**: For large |z|, `np.exp(z)` overflows (e.g., `z=1000` ‚Üí `inf`), while `np.tanh(z)` is stable.\n",
    "\n",
    "In production systems, **always use optimized, stable primitives** (`tanh`, `softmax`, etc.), not manual expansions‚Äîunless you are implementing the primitive itself (which we are not).\n",
    "\n",
    "**Corrected Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 2.0\n",
    "w = -0.5\n",
    "b = 1.0\n",
    "y = 0.8\n",
    "\n",
    "# Forward pass\n",
    "z = w * x + b\n",
    "a = np.tanh(z)            # Use stable built-in\n",
    "L = 0.5 * (a - y)**2\n",
    "\n",
    "# Backward pass (manual gradients)\n",
    "dL_da = a - y\n",
    "da_dz = 1 - a**2\n",
    "dL_dz = dL_da * da_dz\n",
    "dL_dw = dL_dz * x\n",
    "dL_db = dL_dz\n",
    "\n",
    "# Output\n",
    "print(f\"z = {z}\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"L = {L}\")\n",
    "print(f\"dL_dw = {dL_dw}\")\n",
    "print(f\"dL_db = {dL_db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6d41e",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "```\n",
    "z = 0.0\n",
    "a = 0.0\n",
    "L = 0.32\n",
    "dL_dw = -1.6\n",
    "dL_db = -0.8\n",
    "```\n",
    "\n",
    "If your script produces these values, **Phase 1, Step 2 (Scalar Neuron Implementation) is complete**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fd4a6",
   "metadata": {},
   "source": [
    "# **3. From Scalar to Vector ‚Äî The Linear Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348be05",
   "metadata": {},
   "source": [
    "## Why scalar first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382c273",
   "metadata": {},
   "source": [
    "Your implementation of \"*[{name}](#exercise_2_2)*\" is **correct** for a *scalar neuron*‚Äîone input, one weight, one bias, processing one sample. This is exactly the right starting point. The absence of matrix operations is **not a flaw**; it is intentional in Phase 1.\n",
    "\n",
    "However, we must now ask: \n",
    "\n",
    "```{important}\n",
    "**Why begin with scalars if real models use matrices?**\n",
    "```\n",
    "\n",
    "Consider this:  \n",
    "In a vectorized (batched) setting, the forward pass for $B$ samples (rows) and $D$ inputs (features) is:  \n",
    "$Z = XW + b$, where  \n",
    "- $X \\in \\mathbb R^{B \\times D}$\n",
    "- $W \\in \\mathbb R^{D \\times 1}$\n",
    "- $b \\in \\mathbb R$ (broadcasted)\n",
    "- $Z \\in \\mathbb R^{B \\times 1}$\n",
    "\n",
    "The scalar case is the **atomic unit** of this operation. Each element $z_i = x_i¬∑w + b$. If you cannot compute $\\frac {\\partial L}{\\partial w}$ for a single $z$, you cannot correctly derive the batch gradient.\n",
    "\n",
    "Now, examine your code:\n",
    "- You computed $\\frac {\\partial L}{\\partial w} = \\frac {\\partial L}{\\partial z} \\cdot x$.  \n",
    "In the batch case, the gradient becomes:  \n",
    "$\\frac {\\partial L}{\\partial W} = X^T \\cdot \\sigma$, where $\\sigma = \\frac {\\partial L}{\\partial Z} \\in \\mathbb R^{B \\times 1}$.\n",
    "\n",
    "Your scalar $\\frac {\\partial L}{\\partial w} = \\frac {\\partial L}{\\partial z} \\cdot x$ is precisely the $i$-th term in that vectorized sum. So your code is **not just fine ‚Äî it is foundational**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88e3fb",
   "metadata": {},
   "source": [
    "### Moving to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f335daa",
   "metadata": {},
   "source": [
    "But here‚Äôs the critical next step:  \n",
    "**Can you extend this to a batch of 3 samples using only NumPy (no autograd), and verify that your batch gradients match the sum of individual scalar gradients?**\n",
    "\n",
    "Do **not** write the code yet. First, answer:  \n",
    "\n",
    "```{attention}\n",
    "*How would the loss function change for a batch? Would it still be 0.5¬∑(a ‚àí y)¬≤, or must it be aggregated? If aggregated, how ‚Äî and why does that affect the gradient?*\n",
    "```\n",
    "\n",
    "Correct. The batch loss is typically the **mean** of per-sample losses:\n",
    "\n",
    "```{math}\n",
    "L_{\\text{batch}} = \\frac{1}{B} \\sum_{i=1}^{B} \\frac{1}{2} (a_i - y_i)^2\n",
    "```\n",
    "\n",
    "Consequently, the gradient w.r.t. any parameter becomes the **mean** of the per-sample gradients:\n",
    "\n",
    "```{math}\n",
    "\\frac{\\partial L_{\\text{batch}}}{\\partial w} = \\frac{1}{B} \\sum_{i=1}^{B} \\frac{\\partial L_i}{\\partial w}\n",
    "```\n",
    "\n",
    "This is not merely a convention‚Äîit directly impacts **learning dynamics**. Using the mean (instead of sum) makes the gradient magnitude **independent of batch size**, which stabilizes training when B varies.\n",
    "\n",
    "Now, let‚Äôs test your understanding with a concrete micro-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3128e8",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Vector Forward and Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fad69b",
   "metadata": {},
   "source": [
    "Given the following batch of 3 samples:\n",
    "\n",
    "```python\n",
    "X = np.array([[2.0],\n",
    "              [1.5],\n",
    "              [-1.0]])   # Shape: (3, 1)\n",
    "W = np.array([[-0.5]])    # Shape: (1, 1)\n",
    "b = 1.0\n",
    "Y = np.array([[0.8],\n",
    "              [0.5],\n",
    "              [-0.3]])  # Shape: (3, 1)\n",
    "```\n",
    "\n",
    "Write the **forward pass** (compute Z, A, L) and **backward pass** (compute dL_dW, dL_db) **using only NumPy**, without autograd or loops. Use the same tanh activation and MSE loss (mean-reduced over batch).\n",
    "\n",
    "Do **not** encapsulate in functions‚Äîkeep it procedural, like your scalar version.\n",
    "\n",
    "Before you write code:\n",
    "\n",
    "```{attention}\n",
    "*What are the expected shapes of Z, A, dL_dZ, dL_dW, and dL_db?*\n",
    "```\n",
    "\n",
    "```{tip} Answer\n",
    ":class: dropdown\n",
    ":open: false\n",
    "\n",
    "Let‚Äôs recompute **dimensionally**, step by step.\n",
    "\n",
    "Given:\n",
    "- $X$: (3, 1) ‚Äî 3 samples, 1 feature  \n",
    "- $W$: (1, 1) ‚Äî weight matrix (input dim ‚Üí output dim)  \n",
    "- $b$: scalar (broadcasted)\n",
    "\n",
    "**Forward**:\n",
    "- $Z = X @ W + b \\rightarrow (3,1) @ (1,1) = (3,1) \\rightarrow Z \\in \\mathbb R^{3 \\times 1}$ \n",
    "- $A = tanh(Z) \\rightarrow \\text {same shape as Z} \\rightarrow A \\in \\mathbb R^{3 \\times 1}$\n",
    "- $Y \\in \\mathbb R^{3 \\times 1}$\n",
    "\n",
    "**Loss**:\n",
    "- Elementwise error: $(A ‚àí Y) \\rightarrow (3,1)$  \n",
    "- Squared error: $(A ‚àí Y)^2 \\rightarrow (3,1)$  \n",
    "- Mean over batch: $L = \\frac{1}{2B} \\sum_{i=1}^{B} (a_i - y_i)^2 \\rightarrow \\text {scalar}$  \n",
    "\n",
    "**Backward**:\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial A} = \\frac{A - Y}{B} \\rightarrow (3,1)$  \n",
    "  (Because $\\frac{\\partial}{\\partial A} [\\frac{1}{2} \\cdot \\text{mean}((A-Y)^2)] = \\frac{A-Y}{B}$)\n",
    "- $\\displaystyle \\frac{\\partial A}{\\partial Z} = 1 - A^2  \\rightarrow (3,1)$\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial Z} = \\frac{\\partial L}{\\partial A} \\odot \\frac{\\partial A}{\\partial Z}  \\rightarrow (3,1) \\odot (3,1) = (3,1)$\n",
    "\n",
    "Where $\\odot$ represents element-wise multiplication.\n",
    "\n",
    "Now, $\\displaystyle \\frac{\\partial L}{\\partial W}$:\n",
    "\n",
    "- By chain rule: $\\displaystyle \\frac{\\partial L}{\\partial W} = X^\\top \\cdot \\displaystyle \\frac{\\partial L}{\\partial Z}$\n",
    "- $X^\\top$: $(1,3)$, $\\displaystyle \\frac{\\partial L}{\\partial Z}$: $(3,1) \\rightarrow$ result: $(1,1)$\n",
    "\n",
    "Similarly, $\\displaystyle \\frac{\\partial L}{\\partial b} = \\text {sum}$ of $\\displaystyle \\frac{\\partial L}{\\partial Z}$ over batch ‚Üí scalar, but typically kept as $(1,)$ or scalar.\n",
    "\n",
    "So correct shapes:\n",
    "\n",
    "- $Z$: $(3,1)$\n",
    "- $A$: $(3,1)$\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial Z}$: $(3,1)$\n",
    "- $\\displaystyle \\frac{\\partial L}{\\partial W}$: $(1,1)$\n",
    "- $\\displaystyle\\frac{\\partial L}{\\partial b}$: scalar (or $(1,)$ if using array)\n",
    "\n",
    "Your claim that $\\displaystyle \\frac{\\partial L}{\\partial Z}$ is $(1,)$ is incorrect. The gradient w.r.t. $Z$ must have the same shape as $Z$ ‚Äî it's an elementwise derivative.\n",
    "\n",
    "This matters for CUDA: $(3,1)$ implies 3 independent activations, each contributing to the gradient. Mis-shaping breaks vectorization and leads to incorrect memory access patterns on GPU.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a2810",
   "metadata": {},
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177e2ee",
   "metadata": {},
   "source": [
    "Now, back to the exercise:  \n",
    "Given the shape correction, **write the full NumPy code** for forward and backward passes with the provided X, W, b, Y.\n",
    "\n",
    "Keep it procedural. Compute:\n",
    "- Z, A, L\n",
    "- dL_dA, dL_dZ\n",
    "- dL_dW, dL_db\n",
    "\n",
    "Use **matrix operations only** (no loops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f976fce",
   "metadata": {},
   "source": [
    "Consider a **single-layer network** with:\n",
    "- Input batch $\\mathbf{X} \\in \\mathbb{R}^{B \\times d}$ (B = batch size, d = input dim),\n",
    "- Weight matrix $\\mathbf{W} \\in \\mathbb{R}^{d_{\\text{out}} \\times d}$,\n",
    "- Bias $\\mathbf{b} \\in \\mathbb{R}^{d_{\\text{out}}}$,\n",
    "- Output pre-activations $\\mathbf{Z} = \\mathbf{X} \\mathbf{W}^\\top + \\mathbf{1}_B \\mathbf{b}^\\top$\n",
    "\n",
    "Assume a **single output neuron** first ($d_{\\text{out}} = 1$), so $\\mathbf{W} \\in \\mathbb{R}^{1 \\times d}$, $\\mathbf{b} \\in \\mathbb{R}$.\n",
    "\n",
    "Given a loss $L = \\frac{1}{B} \\sum_{i=1}^B \\frac{1}{2}(a^{(i)} - y^{(i)})^2$, what is the **gradient of $L$ with respect to $\\mathbf{W}$** in matrix form?\n",
    "\n",
    "Hint:  \n",
    "- From the scalar case, $\\frac{\\partial L^{(i)}}{\\partial \\mathbf{w}} = \\frac{\\partial L^{(i)}}{\\partial z^{(i)}} \\cdot \\mathbf{x}^{(i)}$\n",
    "- The full gradient is the average over the batch.\n",
    "\n",
    "Express $\\frac{\\partial L}{\\partial \\mathbf{W}}$ using matrix operations (e.g., outer product, matrix multiplication).\n",
    "\n",
    "What is the formula?\n",
    "\n",
    "Now, answer this:  \n",
    "**If we had a batch of 32 inputs, how would the gradient computation for $\\mathbf{W}$ and $\\mathbf{b}$ change in structure?**  \n",
    "\n",
    "Be specific:  \n",
    "- Would you compute gradients per sample then average?  \n",
    "- How does this relate to matrix multiplication in the backward pass?  \n",
    "- What is the shape of $\\frac{\\partial L}{\\partial \\mathbf{W}}$ if $\\mathbf{X} \\in \\mathbb{R}^{32 \\times d}$ and $\\mathbf{W} \\in \\mathbb{R}^{1 \\times d}$?  \n",
    "\n",
    "Explain your reasoning."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "slm_from_scratch",
   "language": "python",
   "name": "slm_from_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
