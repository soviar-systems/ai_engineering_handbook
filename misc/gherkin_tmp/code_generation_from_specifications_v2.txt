

‎Gemini - direct access to Google AI Gemini Code Generation From Specifications https://gemini.google.com/share/73b3cd9198b3  Created with Fast February 16, 2026 at 11:14 PM Published February 17, 2026 at 02:12 PM You said  Explain these concepts. Is it for real that I can use some human language specifications that can be converted to the executable code?  ###  Используем подходы, такие как Model-Driven Development и Domain-Specific Languages (DSL), где спецификации (например, в формате OpenAPI, AsyncAPI или JSON Schema) напрямую преобразуются в исполняемый код. It’s absolutely "for real," though there is a small catch regarding the "human language" part. It’s less like writing a diary entry and more like writing a very structured, high-level blueprint.Here is the breakdown of how this "magic" actually works.1. Model-Driven Development (MDD)In traditional coding, the code is the source of truth. In Model-Driven Development, the model is the boss. You define the logic, data structures, and workflows at a high level, and the computer handles the "grunt work" of writing the boilerplate code.How it works: You create a visual or textual representation of your system.The Benefit: If the requirements change, you update the model and regenerate the code, rather than hunting through 50 different files to change a variable name.2. Domain-Specific Languages (DSL)A DSL is a programming language specialized for a specific "domain" or problem. Unlike General-Purpose Languages (like Python or C++), a DSL doesn't try to do everything—it just tries to do one thing perfectly.Examples you might know: SQL is a DSL for databases. HTML is a DSL for web structure.The "Human" part: DSLs are often designed to be readable by non-programmers (like business analysts) because they use the vocabulary of the industry, not the vocabulary of the computer.3. The "Specifications" (OpenAPI, AsyncAPI, JSON Schema)These are specific types of DSLs used to describe how software should behave or how data should look.SpecificationWhat it describesWhat it generatesOpenAPIHow a REST API works (endpoints, inputs, outputs).Server stubs, Client SDKs, Documentation.AsyncAPIHow message-driven systems (like Kafka or WebSockets) talk.Code to send/receive messages automatically.JSON SchemaThe "shape" of your data (e.g., "Email must be a string").Validation logic and data classes in Java, Python, TS, etc.Export to SheetsIs it really "Human Language"?Sort of. You usually write these in YAML or JSON. While a human can easily read it, it must follow strict rules.Example of OpenAPI (Human-Readable):
get: /users
responses: 200: [UserObject]A code generator takes that tiny snippet and builds 100 lines of complex code to handle networking, security, and data parsing.Why bother?Consistency: The documentation and the code are never out of sync because the code is the documentation.Speed: You can "write" an entire API client in seconds by just pointing a generator at an OpenAPI file.Cross-Platform: You can write one specification and use it to generate code for an iPhone app (Swift), an Android app (Kotlin), and a website (JavaScript) simultaneously.Would you like me to show you a practical example of how a few lines of an OpenAPI spec can turn into a functioning Python or JavaScript client? You said  I can't get it - the computer program writes the code or the LLM writes the code using these specifications? That is a great question. It’s a common point of confusion because we now live in the age of ChatGPT, but Model-Driven Development (MDD) actually existed long before modern AI.The short answer: Traditionally, it’s a rigid computer program (a "Generator"), not an LLM.Here is the difference between the two approaches:1. The Traditional Way: The "Code Generator"This is what people mean when they talk about OpenAPI or AsyncAPI. It’s not "guessing" what you want; it’s following a mathematical blueprint.How it works: A developer writes a generator (a specialized script). This script says: "Every time you see a 'Path' in the specification, create a 'Function' in the Python file."Reliability: 100%. If you run it 1,000 times, you get the exact same code every time.Analogy: It’s like a cookie cutter. You provide the dough (the spec), and the cutter produces the exact same shape every single time. It doesn't "think"; it just transforms format A into format B.2. The Modern Way: The LLM (AI)This is what you see with GitHub Copilot or ChatGPT.How it works: The LLM "reads" your human-language description, predicts what the code should look like based on its training, and types it out.Reliability: Variable. It might add a feature you didn't ask for, or make a logical mistake (hallucination).Analogy: It’s like a sous-chef. You give it a general idea of a dish, and it uses its experience to cook it. It’s creative, but it might forget the salt.Which one is being used in your quote?The quote you provided refers to the Traditional Way.When a company says they use OpenAPI to transform specifications into executable code, they are usually using a tool like Swagger Codegen or openapi-generator. These tools don't use "intelligence"; they use Templates.Why use the "Dumb" Generator instead of AI?In professional software engineering, unpredictability is an enemy.FeatureGenerator (OpenAPI/DSL)LLM (AI)PrecisionExact matches to the spec."Close enough" matches.BugsOnly if the template is broken.Can introduce "creative" bugs.SpeedInstantaneous.Fast, but requires review.Use CaseBanks, APIs, Infrastructure.Prototyping, Creative coding.Export to SheetsThe "Hybrid" FutureToday, many developers use an LLM to write the OpenAPI specification (the human-readable part), and then use a traditional Generator to turn that spec into the final code. This gives you the speed of AI with the safety of a rigid computer program.Would you like to see what a "Generator Template" looks like so you can see how it forces the computer to write the code? You said  Are there specification languages and code generators for Bash for example? Or for Python? And can I use Gherkin user stories specification for writing Bash/Python programs for Linux programs? Yes, you absolutely can, but there is a distinction in how the code is generated for each.For Python, the tools are very mature and "official." For Bash, it's a bit more "DIY," but perfectly possible. Regarding Gherkin (user stories), there is a specific catch you need to know.1. Using Specifications for Python and BashThe most common way to do this is using the OpenAPI specification we discussed earlier.For Python (The Gold Standard)Python is the "favorite child" of code generation. Tools like OpenAPI Generator or FastAPI can take a YAML file and generate:A full web server.Data validation (checking if an email is actually an email).Client libraries (scripts that talk to the server).For Bash (The "Client" approach)There isn't a popular tool that generates a complex Bash "program" logic, but you can generate a Bash Client.The Tool: openapi-generatorThe Result: It generates a .sh script that contains all the curl commands, headers, and error handling needed to talk to a specific service. Instead of writing complex curl logic yourself, you just call ./generated_script.sh get_user --id 5.2. Using Gherkin (User Stories) for Linux ProgramsThis is where things get interesting. You asked if you can use Gherkin (the "Given/When/Then" format) to write programs.The Reality Check: Gherkin is a Testing Specification, not a Coding Specification. It doesn't usually generate the code that does the work; it generates the "shell" for a test that verifies the work.How it looks in practice:If you write a Gherkin story for a Linux tool:GherkinFeature: File Backup
  Scenario: Back up a directory
    Given the directory "/data/docs" exists
    When I run the backup command
    Then a file "backup.tar.gz" should exist in "/backup"
The "Generator" part:For Python: You use a tool called behave. It will read that Gherkin story and generate "Empty Python Functions" (Step Definitions). You then have to fill those functions with the actual Python code.For Bash: You use a tool called behave-bash or Cucumber. It does the same—it maps those "Human" lines to specific Bash scripts or commands.Can you go "Full Automation" (Gherkin → Executable Code)?If you want to bypass the "filling in the blanks" part and go straight from Gherkin → Functional Bash/Python, you are moving out of traditional MDD and into the realm of LLMs (AI).Traditional Tools: Will give you the structure (the skeleton), but you provide the muscles (the logic).AI Tools (like me or GitHub Copilot): Can take a Gherkin file and attempt to write the entire functional script for you.Summary TableGoalFormatPrimary ToolAPI LogicOpenAPI (YAML)openapi-generator (Python/Bash)Data StructureJSON Schemapydantic (Python)User BehaviorGherkinbehave (Python) or bats (Bash)Export to SheetsWould you like me to take a Gherkin "User Story" you've written and generate the Python or Bash "Skeleton" code for it right now? You said  write me examples I can manually test in JupyterLab. Any Gherkin story and Python code to generate the code from this story To test this in JupyterLab, we will use behave, which is the most popular Python framework for Gherkin (Behavior-Driven Development).Since JupyterLab is an interactive environment, we will use the %%writefile magic command to create the necessary files and then run them directly in the cell.1. Install the LibraryFirst, run this in a cell to ensure you have the generator engine:Python%pip install behave
2. Create the Gherkin Story (.feature file)This is the "human language" specification. We will define a simple calculator behavior.Python%%writefile calculator.feature
Feature: Simple Calculator
  Scenario: Add two numbers
    Given I have a calculator
    When I enter 5 and 7
    Then the result should be 12
3. Generate the Python "Skeleton" (The Generator)In a traditional MDD workflow, a tool reads the Gherkin and generates the Step Definitions. We will simulate this by creating a Python file where the Gherkin "sentences" are mapped to Python "functions."Python%%writefile steps/calc_steps.py
from behave import given, when, then

# This is the "Logic" part you would normally write
class Calculator:
    def add(self, a, b):
        return a + b

@given('I have a calculator')
def step_impl(context):
    context.calc = Calculator()

@when('I enter {a:d} and {b:d}')
def step_impl(context, a, b):
    context.result = context.calc.add(a, b)

@then('the result should be {expected:d}')
def step_impl(context, expected):
    assert context.result == expected, f"Expected {expected}, but got {context.result}"
4. Execute the SpecificationNow, we run the behave engine. It will read the "Human Language" story, find the matching Python "Step Definitions," and execute the code to see if it works.Python!behave calculator.feature
What just happened?The Specification: You wrote a story in plain English (Gherkin).The Mapping: You used a "Generator" (the behave library) to link those English sentences to Python logic using Decorators (like @given).The Execution: The computer didn't just "read" the text; it used the text as a command to trigger specific blocks of code.Can you automate the "Code Writing" part?In the example above, I manually wrote the Calculator class. If you want to see how an LLM (like me) can generate that code automatically from the Gherkin story, we can do a "Zero-Code" experiment.Would you like me to act as the "Generator" and write a complete, complex Python script based on a Gherkin story you provide? You said  no magic commands, regular Python and Bash commands for setupt To do this without Jupyter "magic," we will use standard terminal commands and Python scripts. This reflects how a real developer sets up a Behavior-Driven Development (BDD) environment.1. The Environment Setup (Bash)First, create a clean directory for this project and install the behave library. Run these commands in your terminal (or a Jupyter terminal tab):Bash# Create a project structure
mkdir -p gherkin_test/features/steps
cd gherkin_test

# Install the engine
pip install behave
2. Create the Human Specification (Gherkin)We will create a .feature file. This is the "Human Language" part. We'll describe a simple Linux-style file checker.Run this command to create the file:Bashcat <<EOF > features/file_check.feature
Feature: File System Utility
  Scenario: Check if a file exists
    Given a file named "test_data.txt" is created
    When I check for the file's existence
    Then the system should return "Found"
EOF
3. The "Glue" Code (Python Generator Logic)In BDD, we write "Step Definitions." These are Python functions that the behave engine calls when it reads specific lines in your Gherkin file.Create the Python logic file:Bashcat <<EOF > features/steps/file_steps.py
import os
from behave import given, when, then

@given('a file named "{filename}" is created')
def step_impl(context, filename):
    context.filename = filename
    with open(filename, 'w') as f:
        f.write("Hello Gherkin")

@when('I check for the file\'s existence')
def step_impl(context):
    if os.path.exists(context.filename):
        context.result = "Found"
    else:
        context.result = "Not Found"

@then('the system should return "{expected_status}"')
def step_impl(context, expected_status):
    assert context.result == expected_status
    # Cleanup after test
    os.remove(context.filename)
EOF
4. Running the "Executable Specification"Now, you run the behave command from the root of your gherkin_test folder. The computer will read the English text and execute the corresponding Python code.Run this in your terminal:Bashbehave
Expected Output:PlaintextFeature: File System Utility # features/file_check.feature:1
  Scenario: Check if a file exists           # features/file_check.feature:2
    Given a file named "test_data.txt" is created # features/steps/file_steps.py:4
    When I check for the file's existence    # features/steps/file_steps.py:10
    Then the system should return "Found"    # features/steps/file_steps.py:17

1 feature passed, 0 failed, 0 skipped
1 scenario passed, 0 failed, 0 skipped
3 steps passed, 0 failed, 0 skipped
Why this is "Model-Driven"Notice that you didn't run python file_steps.py. You ran behave, which treated your English text as the master script.If you change the Gherkin file to say Then the system should return "Missing", the test will fail. The specification drives the execution.Would you like me to show you how to do the exact same thing but using a Bash script instead of Python to handle the logic? You said  But I have to manually write this:  cat <<EOF > features/steps/file_steps.py  import os  from behave import given, when, then  @given('a file named "{filename}" is created')  def step_impl(context, filename):      context.filename = filename      with open(filename, 'w') as f:          f.write("Hello Gherkin")  @when('I check for the file\'s existence')  def step_impl(context):      if os.path.exists(context.filename):          context.result = "Found"      else:          context.result = "Not Found"  @then('the system should return "{expected_status}"')  def step_impl(context, expected_status):      assert context.result == expected_status      # Cleanup after test      os.remove(context.filename)  EOF Exactly! You’ve hit on the "Big Secret" of software engineering: The computer can't think for you (yet), it can only follow your instructions.When people say "the specification is converted to code," there are actually two different levels of "automation." It sounds like you are looking for the second one.Level 1: The Skeleton (What behave does)This is what you just did. You wrote the English, and the computer gave you the mapping. If you don't write that file_steps.py file, behave will actually yell at you and print a "snippet" for you to copy-paste. It automates the organization, but not the logic.Level 2: Full Generation (The "Real" MDD)This is where you don't write any Python logic. This usually happens in very specific industries (like Banking or Cloud Infrastructure).Instead of Gherkin (which is vague), you use a highly structured specification like OpenAPI.Here is the difference:Gherkin: "When I check if the file exists" → Computer: "I don't know how to check a file on Linux, you have to tell me how using os.path.exists."OpenAPI: get: /user/{id} → Computer: "I know exactly what a GET request is. I will generate 50 lines of Python code to handle the socket, the headers, and the security automatically."Can an LLM bridge the gap?If you want to go from Human Language → Executable Code without manually writing the "Glue Code" (the file_steps.py), you need an "Inference Engine" (an AI).Try this experiment right now:Copy your Gherkin story from the previous message.Paste it into a new prompt and say: "Act as a Code Generator. Write the full file_steps.py for this Gherkin story using the behave library and Python os module."The result: I (the AI) will "convert" your human specification into the logic.Summary: Who writes what?ApproachYou write...The Computer/AI writes...Traditional BDDGherkin + Python LogicThe Test ReportModel-Driven (OpenAPI)The Schema (YAML)The entire functional CodeAI-AssistedGherkinThe Python LogicExport to SheetsSo, to answer your original "Is it for real?"For Business Logic (Gherkin): You still usually write the glue code manually to ensure it's 100% correct.For Standard Infrastructure (APIs/Databases): Yes, the computer can generate 100% of the executable code from a spec.Would you like me to generate a full, executable Bash script based on your Gherkin story so you don't have to write a single line of logic yourself? You said  what should I do now with this Gherkin steps file? Since you’ve already created the Feature file (the human story) and the Steps file (the Python logic), you are now at the Execution stage.Think of this like a "test drive." You have the blueprint and the engine; now you turn the key to see if they work together.1. Run the TestIn your terminal (the same directory where you ran the cat commands), simply type:Bashbehave
2. What to Look ForIf everything is correct, your terminal will turn into a "live document." You will see:The Feature and Scenario names printed out.Each step (Given, When, Then) will be followed by the name of the Python file and the line number that executed it.A summary at the bottom saying "1 scenario passed, 3 steps passed."3. Now, "Break" the Code (The Learning Moment)To truly see why this is an "Executable Specification," try to make the specification and the reality disagree.Open the Feature file: Change the expected result to something wrong.Bashsed -i 's/"Found"/"Missing"/' features/file_check.feature
Run behave again.The Result: It will fail! The computer will show you exactly which "human" requirement failed and provide a Python Traceback showing the AssertionError.4. The "Pro" Move: Auto-Generating SkeletonsYou mentioned earlier that writing the file_steps.py felt like manual labor. Here is a trick developers use:If you write a new scenario in your .feature file that has no Python code yet, run behave.The computer will do this for you:It will realize the steps are missing.It will generate the Python code snippets (the @given, @when, etc.) and print them in your terminal.You just copy-paste those snippets into your steps.py and fill in the "insides."Is this "Executable Code" yet?Right now, you are using these specs for Testing. If you want to use specifications to create the actual production application (the part the user actually touches), you would move away from Gherkin and toward OpenAPI or Protobuf.Would you like me to show you how a single OpenAPI YAML file can generate a 100% functional Python web server without you writing a single @ decorator? You said  but how does this help me write the program? I do not understand the usefulness of this output text The confusion you’re feeling is the "Aha!" moment every developer has when they first realize that BDD (Behavior-Driven Development) is a testing tool, while MDD (Model-Driven Development) is a building tool.The output text from behave isn't the program. It's a receipt proving your program does what you promised in the Gherkin story.Here is why this is actually useful (and where the "real" code generation happens).1. It forces the "Blueprint" firstIf you just start typing Python, you might forget to handle an error or a specific edge case. By writing the Gherkin story first, you are creating a contract.The Gherkin: "The user must be over 18 to enter."The Python: You are now forced to write the logic that checks the age.2. The "Real" Automation: OpenAPIIf you want the computer to actually write the program for you, you stop using Gherkin and use OpenAPI. This is where the magic happens.Try this mental experiment:
Imagine you want to build a system for a library.You write a YAML file (the Specification) that says: "I need a way to GET a book by its ID and POST a new book."You run a tool called openapi-generator.Boom: The tool creates 500 lines of Python code—including the web server, the database connections, and the security checks.You didn't write a single line of Python. The specification became the program.3. Why use Gherkin then?Gherkin is for the logic that doesn't exist yet.Standard stuff (Web servers, APIs, Databases) → Use OpenAPI to generate the code.Custom stuff (How your specific "File Backup" logic works) → Use Gherkin to make sure your custom code actually works.Comparison: Which one "Writes the Program"?MethodDoes it write the logic?What is it for?Gherkin (Behave)No. You write the logic; it verifies it.Ensuring your human logic matches the business goal.OpenAPI/DSLYes. It generates the entire functional structure.Standard plumbing (APIs, Data, Infrastructure).LLM (AI)Yes. It guesses the logic from your text.Rapid prototyping and "filling in the blanks."Export to SheetsWhat is your goal?If your goal is to write a program faster, I can show you how to use an OpenAPI spec to generate a functional Python API in 30 seconds.If your goal is to make sure your program has no bugs, we stick with Gherkin.Would you like me to give you a 10-line OpenAPI YAML file and the command to turn it into a 100% working Python web server? You said  Okay, I got this output, the steps file, the specification. What are my next steps? My final goal is to develop a program that does what the user story says The "Aha!" moment happens when you realize that Gherkin is a shell, and you are currently the engine.Right now, you have a test suite that proves your program works, but you don't have the standalone program yet. In professional development, we use these steps to "grow" the real application.Here is your roadmap to turn that "output text" into a finished Linux program.1. Extract the Logic into a Main ProgramIn your steps/file_steps.py, you wrote some Python code inside functions like @when. That code is your Business Logic. To make a real program, you move that logic into its own file.Create your actual program (my_tool.py):Pythonimport os
import sys

def check_file(filename):
    """The actual logic we verified with Gherkin"""
    if os.path.exists(filename):
        return "Found"
    else:
        return "Not Found"

if __name__ == "__main__":
    # This allows you to run it from the command line: python my_tool.py test.txt
    target = sys.argv[1]
    print(check_file(target))
2. Refactor the Steps to use the Real ProgramNow, instead of writing "fake" logic inside the Gherkin steps, you make the steps call your real program. This is called Integration Testing.Update your features/steps/file_steps.py to use the real script:Pythonfrom behave import given, when, then
import subprocess # We use this to run the actual script

@given('a file named "{filename}" is created')
def step_impl(context, filename):
    context.filename = filename
    with open(filename, 'w') as f: f.write("data")

@when('I check for the file\'s existence')
def step_impl(context):
    # RUN THE ACTUAL PROGRAM instead of writing logic here
    result = subprocess.run(['python', 'my_tool.py', context.filename], capture_output=True, text=True)
    context.result = result.stdout.strip()

@then('the system should return "{expected_status}"')
def step_impl(context, expected_status):
    assert context.result == expected_status
3. The "Loop" (The Secret to Fast Development)This is how developers use this to "build" the program:Add a new Story: Add a line to your .feature file (e.g., "When the file is a directory, return 'IsDirectory'").Run behave: It will fail (because your my_tool.py doesn't know about directories yet).Update my_tool.py: Write the code to handle directories.Run behave again: If it turns green, you are done.Why do this?Because in a month, when your program has 5,000 lines of code, you can run behave and know within 2 seconds if you accidentally broke the "File Existence" feature while adding a "Delete" feature. The Gherkin spec is your safety net.Summary of your "Final Program"A finished professional project using this method looks like this:my_tool.py — The Program (What you give to users).features/ — The Requirements (Gherkin files).features/steps/ — The Proof (The code that connects the Requirements to the Program).Would you like me to show you how to bundle my_tool.py into a real Linux command that someone can install and run? You said  so, this TDD? Close! It is actually BDD (Behavior-Driven Development), which is the "evolved cousin" of TDD.The distinction is small but very important for how you approach your project.1. TDD vs. BDD: The Simple DifferenceTDD (Test-Driven Development): You focus on the implementation.Question: "Does this specific function return an integer?"Language: Pure Python code (assert add(2, 2) == 4).BDD (Behavior-Driven Development): You focus on the user's goal.Question: "Can the user successfully back up their files?"Language: Human-readable Gherkin ("Given a user has a file...").2. How this helps you build the programYou asked earlier, "How does this help me write the program?" In BDD, the process follows a specific loop called "Red-Green-Refactor."RED (The Spec): You write the Gherkin story. You run behave. It fails because the program doesn't exist yet. This defines exactly "what" needs to be built.GREEN (The Code): You write just enough Python code in my_tool.py to make the Gherkin test pass. You aren't guessing what to write; you are fulfilling a contract.REFACTOR (The Cleanup): Now that it works, you clean up your code. You run behave again to make sure you didn't break the "behavior" while cleaning.3. The "Executable" PartThe reason the quote you started with says these specs are "converted to executable code" is that in a professional pipeline, the code is not allowed to be "finished" until the specification says so.If you are building this for a Linux environment:The Spec is your "Definition of Done."The Program (my_tool.py) is your "Product."The Steps are the "Glue" that proves the two match.Your Practical Next StepSince you have the files, your "real" work starts now:Open my_tool.py.Write a new feature (e.g., a function to delete a file).Stop! Before you write the Python code for it, go to your .feature file and write a new Scenario: Delete a file.Run behave, watch it fail, and then write the Python code.This is how you ensure your program does exactly what the user story says, with zero "extra" junk code.Would you like me to help you write a more complex "Scenario" for your program, like handling errors when a file is read-only? You said  what are the classic books or courses on BDD? Since BDD is more about communication and design than just "writing code," the classic materials focus heavily on how to bridge the gap between business talk and technical implementation.Here are the "gold standards" for learning BDD:1. The "Must-Read" BooksThese books are considered the foundation of the movement."Specification by Example" by Gojko Adzic This is arguably the most important book on the topic. It doesn't focus on tools like Python or Bash; it focuses on how to have conversations that result in clear specifications. It won the Jolt Award for best book in its year.+1"The Cucumber Book" by Matt Wynne and Aslak Hellesøy Even though it uses Ruby for its examples, it is the "Bible" of Gherkin. It explains how to write expressive features and how to organize your step definitions properly. The principles apply 100% to your Python/behave setup."BDD in Action" (2nd Edition) by John Ferguson Smart This is a massive, comprehensive guide. It covers everything from the initial "user story" conversation to the technical architecture of automation. It’s perfect if you want to see how BDD fits into a large-scale project.2. Essential Online Courses & ResourcesIf you prefer learning by doing, these are the most respected paths:Cucumber School (Free/Paid): The creators of the Cucumber tool (the original Gherkin engine) offer high-quality video lessons. They have a specific track for BDD with Python, which aligns exactly with the behave workflow we discussed."Test-Driven Development (TDD) and Behavior-Driven Development (BDD)" on Coursera/IBM: A very structured academic approach to understanding the lifecycle you just practiced (Red-Green-Refactor).The "Discovery" Workshops (Concept): Look up "Example Mapping" by Matt Wynne. It’s a 20-minute technique to turn a user story into Gherkin using colored index cards. It is the fastest way to "do" BDD without a computer.3. The "Holy Grail" Philosophy: "The Discovery, Formulation, Automation" TriadTo master BDD, remember these three stages that these books often emphasize:Discovery: Having a conversation (usually called "The Three Amigos") to decide what to build.Formulation: Writing that down in Gherkin (the .feature files).Automation: Writing the "Glue Code" (the steps.py) to make it executable.Pro Tip for your Python Project:When you search for resources, look for the "Cucumber" ecosystem. While you are using behave (which is the Python-specific tool), the logic, the language (Gherkin), and the philosophy are identical to Cucumber.Would you like me to find a specific "Example Mapping" template for your next user story to help you practice the "Discovery" phase? You said  is this approach still valuable in the era of AI Code Generetation Egnineering with AST/CST in sandboxing and mulit-agent environments or there are more suitable approaches? In the era of AI Code Generation Engineering, the "classic" BDD/Gherkin approach is not becoming obsolete; it is actually being supercharged as the foundational layer for AI agents.While tools like AST/CST (Abstract/Concrete Syntax Trees), sandboxing, and multi-agent systems handle the "how" of coding, the Gherkin/DSL layer has evolved to handle the "what" and the "why."1. The Modern Shift: Spec-Driven Development (SDD)The industry is moving from just "writing tests" to Spec-Driven Development. In this world, the specification (Gherkin/OpenAPI) is the "prompt" that an AI agent uses to generate code.The Problem with AI: AI is a "stochastic parrot"—it can guess code well, but it often misses business nuances.The Solution (Gherkin): Gherkin provides a mathematical boundary for the AI. Instead of asking an AI to "write a backup script," you give it a Gherkin scenario. The AI then uses AST parsing to ensure the generated code's structure matches the specification exactly.2. How AST/CST and Sandboxing fit inIn modern multi-agent environments, the "classic" approach you just learned is the first step in a high-tech pipeline:TechnologyRole in the AI EraGherkin/DSLThe Source of Truth. The "Contract" that the AI must fulfill.Multi-Agent SystemsOne agent writes the spec, one generates code, one generates tests.AST/CST AnalysisAutomatically checks if the AI-generated code violates any architectural rules.SandboxingThe environment where an agent runs behave to see if its own code passed.Export to Sheets3. Is there a "More Suitable" Approach?While Gherkin is still king for human-readable logic, new "Spec-as-Source" tools are emerging that are even more integrated with AI:Tessl & Spec-kit: These tools treat the specification as the primary artifact. You edit the spec, and the AI agents automatically update the code in a sandbox, using AST to ensure no regressions occur.Agentic BDD: Systems where an AI agent "reads" your Gherkin, writes the steps.py (the glue code) itself, runs it in a sandbox, and iterates until the "Green" light appears.The Verdict: You aren't learning an "old" way; you are learning the syntax of the command for the next generation of AI agents. If you can't write a clear Gherkin story, you won't be able to "engineer" an AI agent to build a complex system.Would you like me to show you how to prompt an AI agent specifically using your Gherkin file to generate a more complex, sandboxed Python application?Behavior-Driven Development (BDD) with AI Agents
This video explores how modern AI agents can interpret Gherkin scenarios to automate test generation and execution, demonstrating the continued relevance of BDD in the age of generative AI.5 - Cucumber and Gherkin, AI agents with permission to test - Branislav Majernik - YouTubeOpenSlava · 244 views Google Privacy Policy  Opens in a new window  Google Terms of Service  Opens in a new window  Your privacy & Gemini Apps  Opens in a new window Gemini may display inaccurate info, including about people, so double-check its responses. Continue this chat Google AccountVadim Rudakovlefthand67@gmail.comCopy public linkReport