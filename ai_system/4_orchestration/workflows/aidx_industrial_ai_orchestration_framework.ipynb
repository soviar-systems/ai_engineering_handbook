{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1b5753-8c14-46b3-ba22-f21d020712e9",
   "metadata": {},
   "source": [
    "# The `aidx` Industrial AI Orchestration Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73064eb4-868e-42ca-ad99-308b81852670",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Owner: Vadim Rudakov, lefthand67@gmail.com  \n",
    "Version: 0.1.0  \n",
    "Birth: 2026-01-14  \n",
    "Last Modified: 2026-01-14\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a0986-0658-4efd-9917-407a6dbe4864",
   "metadata": {},
   "source": [
    "> \"aidx\" stands for \"aider extended\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81852fc9-e2f7-4938-af82-616e2a89e77f",
   "metadata": {},
   "source": [
    "This handbook serves as the definitive standard for AI-assisted engineering within the organization. This framework is designed to provide production-grade velocity on local hardware by solving the critical \"Switching Moment\" bottleneck—where large context histories from cloud models overload local GPU VRAM.\n",
    "\n",
    ":::{seealso}\n",
    "> 1. [\"ADR 26005: Formalization of Aider as the Primary Agentic Orchestrator\"](/architecture/adr/adr_26005_formalization_of_aider_as_primary_agentic.md)\n",
    "> 2. [\"VIM in AI Era: Hybrid Setup with Ollama and Aider\"](/tools/docs/ai_agents/01_vim_in_ai_era_hybrid_setup_with_ollama_and_aider.ipynb)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ffdca-6582-4c7b-9058-d4caa4f9b1e6",
   "metadata": {},
   "source": [
    "## **1. The Research-Apply Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a862fe-5708-4316-829d-5670d5c3fab5",
   "metadata": {},
   "source": [
    "> ISO 29148: Appropriateness\n",
    "\n",
    "The `aidx` framework moves away from **passive** AI chat toward an **Active (Agentic) Retrieval** model. We decouple the \"finding of truth\" from the \"application of code changes\" to ensure that local models remain focused, accurate, and stable.\n",
    "\n",
    "> We decouple \"finding truth\" from \"writing code\" to ensure local hardware stability and architectural alignment.\n",
    "\n",
    "| Phase | Component | Action | ADR / Standard |\n",
    "| --- | --- | --- | --- |\n",
    "| **1. Research** | **Researcher** | A lightweight local agent (e.g., `ministral`) identifies relevant context from the 1M+ token Knowledge Base via vector DB (Qdrant/pgvector). | {term}`ADR 26004` |\n",
    "| **2. Planning** | **Architect** | A high-reasoning cloud LLM (e.g., Gemini 3 Flash) processes the research results to generate a precise `artifacts/plan.md`. | {term}`ADR 26005` |\n",
    "| **3. Execution** | **Editor** | A local SLM (e.g., `qwen2.5-coder:14b`) applies the plan to the codebase in a clean context state to prevent GPU OOM. | {term}`ADR 26005` |\n",
    "| **4. Validation** | **CI/CD Gates** | Automated `pre-commit` and `gitlint` hooks verify code integrity, architectural tags, and Conventional Commit standards. | {term}`ADR 26002` {term}`ADR 26003` |\n",
    "| **5. Review** | **Forensic** | Human-led verification of changes. | SWEBOK V4.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d886b-821c-4cf4-bee4-f2e2287ef5d5",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  look: handDrawn\n",
    "  theme: redux\n",
    "---\n",
    "graph TD\n",
    "    subgraph \"Phase 1: Research (Local Context)\"\n",
    "        A[Knowledge Base / RAG] -->|Query| B(Researcher: **local** Ministral)\n",
    "        B -->|Retrieve Chunks| C{Context Window Check}\n",
    "    end\n",
    "\n",
    "    subgraph \"Phase 2: Planning (Cloud Reasoning)\"\n",
    "        C -->|Grounded Prompt| D[Architect: **cloud** Gemini 3 Flash]\n",
    "        D -->|Draft Strategy| E[File: artifacts/plan.md]\n",
    "    end\n",
    "\n",
    "    subgraph \"Phase 3: Execution (Local VRAM Isolation)\"\n",
    "        E -->|Clean State Input| F[Editor: **local** Qwen2.5-Coder 14B]\n",
    "        F -->|Atomic Write| G[Staged Code Changes]\n",
    "    end\n",
    "\n",
    "    subgraph \"Phase 4: Validation (CI/CD Gates)\"\n",
    "        G -->|Pre-commit| H[Python OOP Hooks]\n",
    "        H -->|Gitlint| I[ArchTag/Tier Check]\n",
    "    end\n",
    "\n",
    "    subgraph \"Phase 5: Review (Human/Forensic)\"\n",
    "        I -->|Success| J[Final Commit/Merge]\n",
    "        I -->|Fail| B\n",
    "    end\n",
    "\n",
    "    style D fill:#f9f,stroke:#333,stroke-width:2px\n",
    "    style F fill:#bbf,stroke:#333,stroke-width:2px\n",
    "    style E stroke-dasharray: 5 5\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7283159-eefb-4331-947c-9d8771b13bf0",
   "metadata": {},
   "source": [
    "## **2. Resource Optimization & VRAM Isolation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016b9dd-e7ef-4fa4-a11a-c1da9b448851",
   "metadata": {},
   "source": [
    "> {term}`ADR 26005`\n",
    "\n",
    "This hybrid model is specifically engineered for **bare-metal systems with limited VRAM**.\n",
    "\n",
    "* **Role Separation**: Expensive \"Architect\" tokens are used for structural decisions in the cloud, while the local GPU is reserved exclusively for the \"Editor\" model and local inference tests.\n",
    "* **The Bridge Pattern**: The Editor is initialized with a **clean context**, receiving only the specific instructions and target files from the Architect. This prevents the  VRAM growth typical of long Aider sessions.\n",
    "* **Context Gating**: Local sessions are strictly limited via `max-chat-history-tokens: 2048` to ensure hardware stability.\n",
    "\n",
    "Specifically, the transition from **Phase 2 (Architect)** to **Phase 3 (Editor)** must be a \"Hard Reset.\"\n",
    "\n",
    "* **Mechanism**: The Editor instance of Aider is launched without the `--message-file` history used by the Architect. It receives only the `artifacts/plan.md` as its primary instruction.\n",
    "* **Benefit**: This keeps the KV cache usage on your local GPU below 4GB, leaving maximum headroom for the 14B model weights.\n",
    "\n",
    ":::{tip} Role Configuration Example\n",
    ":class: dropdown\n",
    "```{code} bash\n",
    ":linenos:\n",
    ":filename: ~/.aider.conf.yml\n",
    "\n",
    "# Cloud Architect for complex reasoning\n",
    "model: gemini/gemini-2.5-flash\n",
    "\n",
    "# Local Editor for hardware-aware execution\n",
    "editor-model: ollama_chat/qwen2.5-coder:14b-instruct-q4_K_M\n",
    "\n",
    "# Strict history gating to prevent OOM (tests needed)\n",
    "max-chat-history-tokens: 2048\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a1dbf-a421-43ec-9455-b86f0e757626",
   "metadata": {},
   "source": [
    "## **3. Agentic RAG: Pre-Flight Knowledge Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9a7d6-46ad-4829-884b-6f0025f07b62",
   "metadata": {},
   "source": [
    "> {term}`ADR 26004`\n",
    "\n",
    "**The Problem:**  \n",
    "- Standard RAG (e.g., within `aider` or Open WebUI) faces \"Context Overload.\" 1M tokens exceed the functional window of local models like `qwen2.5-coder`, leading to noise and hallucinations.\n",
    "- Manual file addition is prone to human error and \"Knowledge Debt\". The `aidx` pattern automates context gathering to bridge the gap between a 1M+ token KB and a local context window.\n",
    "\n",
    ":::{note} **The Solution**  \n",
    "An **Agentic RAG \"Pre-Flight\" Wrapper** (the `aidx` pattern). This decouples \"Knowledge Retrieval\" from \"Code Generation\".\n",
    ":::\n",
    "\n",
    "* **Namespace Partitioning**: Retrieval is split into `Global_Workflows` and `Project_Specific` collections to maintain high precision.\n",
    "* **Stage Injection**: Retrieved snippets are injected into the initial Architect context via `--message-file` or `--read`, ensuring the plan is grounded in current organizational standards.\n",
    "\n",
    "This phase links retrieval to commit integrity:\n",
    "\n",
    "* **Requirement**: Every automated code change must cite the documentation chunk retrieved in Phase 1.\n",
    "* **Enforcement**: Our `ArchTag` system ({term}`ADR 26003`) ensures that if a change was driven by a RAG retrieval, the commit body contains a traceability link (e.g., `REF: [Workflow-Standard-04]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53808911-b6a4-4a44-adbc-96dffb3653a5",
   "metadata": {},
   "source": [
    "## **4. Engineering Standards & Automation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac34ab1-8a1b-4dd5-b050-8d16786e8220",
   "metadata": {},
   "source": [
    "> {term}`ADR 26001`, {term}`ADR 26002`, {term}`ADR 26003`\n",
    "\n",
    "To prevent \"Orchestration Debt,\" all wrappers and automation logic must adhere to industrial-grade Python standards.\n",
    "\n",
    "* **Python 3.13+ OOP**: All hooks and AI wrappers are written in Object-Oriented Python to ensure logic is encapsulated and testable.\n",
    "* **Reliability through `pytest`**: Every tool must have a corresponding test suite to simulate Git states and prevent workflow regressions.\n",
    "* **Three-Tier Validation**:\n",
    "    * **Tier 1**: Branch naming conventions checked via `pre-commit`.\n",
    "    * **Tier 2**: Conventional Commit headers enforced by `gitlint`.\n",
    "    * **Tier 3**: Conditional **Architectural Tags** (ArchTags) required in commit bodies for refactors or breaking changes to provide long-term justification.\n",
    "    :::{seealso}\n",
    "    > [\"Production Git Workflow Standards\"](/tools/docs/git/01_production_git_workflow_standards.ipynb)\n",
    "    :::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa211c8b-7363-4654-920e-d8b03827b92e",
   "metadata": {},
   "source": [
    "## **5. Team Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e36e9b-39bb-4f0b-9699-03b1f3f3a5c2",
   "metadata": {},
   "source": [
    "1. **Environment Sync**: Run `configure_repo.sh` to install the `pre-commit` framework via `uv`.\n",
    "2. **Configuration**: Ensure `~/.aider.conf.yml` mirrors the Hybrid role separation (Architect: Cloud / Editor: Local).\n",
    "3. **Execution**: Launch tasks via the `aidx` Python wrapper to ensure the Research-Apply pipeline is strictly followed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910ce56-b86d-46dd-aa42-dce3f9a3b7b8",
   "metadata": {},
   "source": [
    "## **6. Potential Technical Debt & Mitigations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48262cd4-3f0c-4b86-8ff3-a3a5ee3b3e4d",
   "metadata": {},
   "source": [
    "* **Execution Latency:** Python startup (~100ms) and RAG research (2–5s) add overhead.\n",
    "    * *Mitigation:* Defer heavy imports; active research is faster than manual searching.\n",
    "\n",
    "* **Embedding Drift:** If the KB isn't updated, the Researcher will retrieve outdated advice.\n",
    "    * *Mitigation:* Automated re-indexing triggers upon KB changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5d69d-9c3b-4ad7-80c9-2f23c820e103",
   "metadata": {},
   "source": [
    "## **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9a67a-6f53-4e83-a8c0-49fbee390790",
   "metadata": {},
   "source": [
    ":::{glossary}\n",
    "ADR 26001\n",
    ": [Use of Python and OOP for Git Hook Scripts](/architecture/adr/adr_26001_use_of_python_and_oop_for_git_hook_scripts.md)\n",
    "\n",
    "ADR 26002\n",
    ": [Adoption of the Pre-commit Framework](/architecture/adr/adr_26002_adoption_of_pre_commit_framework.md)\n",
    "\n",
    "ADR 26003\n",
    ": [Adoption of gitlint for Tiered Workflow Enforcement](/architecture/adr/adr_26003_adoption_of_gitlint_for_tiered_workflow.md)\n",
    "\n",
    "ADR 26004\n",
    ": [Implementation of Agentic RAG for Autonomous Research](/architecture/adr/adr_26004_implementation_of_agentic_rag_for_autonom.md)\n",
    "\n",
    "ADR 26005\n",
    ": [Formalization of Aider as the Primary Agentic Orchestrator](/architecture/adr/adr_26005_formalization_of_aider_as_primary_agentic.md)\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
