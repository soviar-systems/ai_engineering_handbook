{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c3a06b-dc9f-42ee-83cd-1922702ed60c",
   "metadata": {},
   "source": [
    "# LLM Usage Patterns: Chats, Workflows, and Agents in AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e3049",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Owner: Vadim Rudakov, lefthand67@gmail.com  \n",
    "Version: 0.1.4  \n",
    "Birth: 2025-10-19  \n",
    "Last Modified: 2026-01-10\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4aa84c",
   "metadata": {},
   "source": [
    "Large Language Models (LLMs) like GPT have transformed how we build AI applications. But to design effective, production-ready AI systems, engineers must understand the **theoretical and practical differences** between three fundamental usage patterns:\n",
    "\n",
    "* **Chats**\n",
    "* **Workflows**\n",
    "* **Agents**\n",
    "\n",
    ":::{seealso}\n",
    "- [Choosing Model Size for Chats, Workflows, and Agents: Model Size, Reasoning, and Optimization](/ai_system/2_model/selection/choosing_model_size.md)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e3da4",
   "metadata": {},
   "source": [
    "## 1. What is a Chat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38087a2",
   "metadata": {},
   "source": [
    "### Theoretical View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9d901",
   "metadata": {},
   "source": [
    "A **chat** primarily involves conversational interaction: the AI model responds directly to user inputs with natural language outputs. It focuses on understanding intent and generating coherent, context-aware text.\n",
    "\n",
    "* Chat is **reactive**: it awaits user input and replies.\n",
    "* Interaction is typically a **single or multi-turn dialogue**.\n",
    "* Behavior is driven by **prompt engineering** and context history management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22db305",
   "metadata": {},
   "source": [
    "### Practical Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322da74e",
   "metadata": {},
   "source": [
    "* Usually implemented as a single LLM call wrapped with minimal conversational context management (history, token limits).\n",
    "* **Operational Footprint:** **Low Latency** and **Low Cost** per query.\n",
    "\n",
    "**Example:** A customer support chatbot answering product FAQs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d70c9a",
   "metadata": {},
   "source": [
    "## 2. What is a Workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3f161",
   "metadata": {},
   "source": [
    "### Theoretical View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f15fb",
   "metadata": {},
   "source": [
    "Workflows use LLMs as components within a **predefined, structured pipeline** of AI and non-AI tasks.\n",
    "\n",
    "* Consists of **sequential or conditional steps**.\n",
    "* Each step solves a **specific subtask**, like classification, summarization, or data extraction.\n",
    "* The process is **deterministic and scripted** by human engineers.\n",
    "\n",
    "> **Note on Determinism:** While workflows may include conditional branching and error handling that appear dynamic, their decision logic is entirely scripted by human engineers. This means workflows are **deterministic** and lack genuine autonomy â€” they do not adapt or revise their sequence of steps based on situational understanding beyond predefined, hard-coded rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c51a65",
   "metadata": {},
   "source": [
    "### Practical Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b4d80",
   "metadata": {},
   "source": [
    "* Implemented as **Python scripts or orchestrated pipelines** (e.g., using frameworks like LangChain Pipelines).\n",
    "* Requires management of inputs/outputs between steps, error checking, and optional fallback mechanisms.\n",
    "* **Operational Footprint:** **Moderate Latency** and **Moderate Cost** due to multiple sequential LLM calls.\n",
    "\n",
    "**Example:** A resume screening system that extracts skills, scores relevance, then generates a summary report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9ca49",
   "metadata": {},
   "source": [
    "## 3. What is an Agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed991d5",
   "metadata": {},
   "source": [
    "### Theoretical View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0370d",
   "metadata": {},
   "source": [
    "Agents are **autonomous AI systems** that perceive environment inputs, plan actions, dynamically select and execute tasks, and adapt based on context and feedback.\n",
    "\n",
    "The agent's power comes from integrating **LLM reasoning with external tool/API invocation**. It has dynamic **decision-making capabilities**, choosing the *next* step based on the *result* (observation) of the *previous* step, enabling **iterative self-correction and feedback loops**.\n",
    "\n",
    "In sophisticated agent architectures, the **planner-executor model** is crucial: the LLM (planner) generates the next high-level decision, and the executor system performs the specific action (tool/API call) and reports the observation back to the LLM for the next planning cycle. This enables true self-direction beyond scripted automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760c5ec",
   "metadata": {},
   "source": [
    "### Practical Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2003ba",
   "metadata": {},
   "source": [
    "* Implemented as complex, iterative software architectures integrating LLMs with external APIs, databases, and tools.\n",
    "* Requires robust **control flow logic**, state management, and tool parsing.\n",
    "* **Operational Footprint:** **High Latency** and **High Cost** due to the iterative nature of the decision loop, high token usage for history/reflection, and multiple sequential API calls.\n",
    "\n",
    "**Example:** A virtual assistant that plans a trip by querying weather, dynamically booking flights based on availability, and updating the itinerary as new information arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bc438",
   "metadata": {},
   "source": [
    "## 4. Key Differences Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6a15a",
   "metadata": {},
   "source": [
    "| Aspect | Chat | Workflow | Agent |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Purpose** | Human-like conversation | Structured multi-step tasks | **Autonomous task planning & execution** |\n",
    "| **Architecture** | Single LLM interaction | Fixed pipeline of modular steps | **Dynamic, iterative control loop** with tools & APIs |\n",
    "| **Autonomy** | Low; reactive | Medium; scripted process (deterministic) | **High; adaptive and self-directed** (non-deterministic sequence) |\n",
    "| **Complexity** | Simple | Moderate | **High** |\n",
    "| **Operational Cost** | Low | Moderate | **High** (Token/Latency) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c5a0c",
   "metadata": {},
   "source": [
    "## 5. Practical Tips for AI Engineers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cc4a5",
   "metadata": {},
   "source": [
    "* **Start with chats** if your need is straightforward conversational AI.\n",
    "* **Use workflows** for automating well-defined multi-step AI tasks where the execution sequence is known and can be specified in advance.\n",
    "* **Build agents** when your system needs to autonomously plan, choose tools, and adapt its execution path based on intermediate results and complex context.\n",
    "* **Operational Constraint:** Remember that complexity scales with operational cost and latency. **Agents** are the most flexible but typically incur the highest latency and token consumption due to iterative self-reflection and decision-making calls.\n",
    "* **Production Agents:** Advanced agents designed for production require strong evaluation, guardrails (like sandboxed tool execution), and robust observability mechanisms, including human-in-the-loop checkpoints, to ensure safety, correctness, and compliance in autonomous decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3250ec0",
   "metadata": {},
   "source": [
    "## 6. Example Code Skeletons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681d7b3",
   "metadata": {},
   "source": [
    "### Chat (Python + Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa650212",
   "metadata": {},
   "source": [
    "```python\n",
    "user_input = \"What are the benefits of solar energy?\"\n",
    "prompt = f\"Answer in a friendly tone: {user_input}\"\n",
    "response = llm.call(prompt)\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ab0e6",
   "metadata": {},
   "source": [
    "### Workflow (Chained Steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd5962",
   "metadata": {},
   "source": [
    "```python\n",
    "def extract_topics(text):\n",
    "    return llm.call(f\"Extract main topics from: {text}\")\n",
    "\n",
    "def summarize(topics):\n",
    "    return llm.call(f\"Write a summary based on: {topics}\")\n",
    "\n",
    "business_question = \"Explain renewable energy trends.\"\n",
    "topics = extract_topics(business_question)\n",
    "summary = summarize(topics)\n",
    "print(summary)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49e600",
   "metadata": {},
   "source": [
    "### Agent (Iterative Decision + Tool Invocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5ea4b-810d-4d91-91db-31fc90bfb040",
   "metadata": {},
   "source": [
    "This architecture demonstrates the iterative nature where the LLM is called repeatedly to make the next decision based on the current state and observed results.\n",
    "\n",
    "```python\n",
    "class Agent:\n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "\n",
    "    def act(self, user_input, max_steps=5):\n",
    "        current_state = {'task': user_input, 'history': []}\n",
    "\n",
    "        for step_count in range(max_steps):\n",
    "            # 1. LLM plans the NEXT action based on the *current state*\n",
    "            decision = llm.call(f\"Based on history {current_state['history']}, what is the best next action for task: {user_input}?\")\n",
    "            \n",
    "            tool_name, args = parse_decision(decision) # Hypothetical function to parse tool choice\n",
    "\n",
    "            if tool_name == \"FINISH\":\n",
    "                print(\"Task complete.\")\n",
    "                return current_state.get('result', \"Success.\")\n",
    "\n",
    "            if tool_name in self.tools:\n",
    "                # 2. Execute the action (Tool invocation)\n",
    "                result = self.tools[tool_name](args)\n",
    "                \n",
    "                # 3. Update state with the observation/result for the next loop\n",
    "                current_state['history'].append({'action': tool_name, 'observation': result})\n",
    "            else:\n",
    "                return f\"Error: Invalid tool {tool_name} used.\"\n",
    "        \n",
    "        return \"Max steps reached without finishing the task.\"\n",
    "\n",
    "# Hypothetical usage\n",
    "agent = Agent(tools={'weather_api': get_weather, 'email': send_email})\n",
    "agent.act(\"Schedule outdoor event next week\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
